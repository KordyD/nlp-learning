{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.autos', 'sci.med',  'talk.politics.mideast']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]\n",
    "\n",
    "# lemmatized_collection_POS = [[{token.lemma_.lower(): token.pos_} for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT'] for text in news_groups.data]\n",
    "\n",
    "# print(lemmatized_collection)\n",
    "# print(lemmatized_collection_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_adj_nouns = vectorizer.fit_transform(lemm_texts_nouns_adj)\n",
    "vectors_nouns = vectorizer.fit_transform(lemm_texts_nouns)\n",
    "\n",
    "euclidean_distance_matrix = euclidean_distances(vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(vectors_adj_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(vectors_nouns)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(vectors_adj_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(vectors_nouns)\n",
    "\n",
    "jaccard_similarity_matrix = DistanceMetric.get_metric('jaccard').pairwise(vectors)\n",
    "jaccard_similarity_matrix_adj_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_adj_nouns)\n",
    "jaccard_similarity_matrix_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix, jaccard_similarity_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns, jaccard_similarity_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns, jaccard_similarity_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters):\n",
    "    scores = {}\n",
    "    result = []\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        clusters = KMeans(n_clusters=n_clusters, n_init=10, random_state=i)\n",
    "        clusters.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "\n",
    "    for metric in scores:\n",
    "        max = np.max(scores[metric])\n",
    "        min = np.min(scores[metric])\n",
    "        avg = np.mean(scores[metric])\n",
    "\n",
    "        result.append(f'{metric}\\nMax: {max} iter: {scores[metric].index(max) + 1}\\nMin: {min} iter: {scores[metric].index(min) + 1}\\nAvg: {avg}\\n')\n",
    "        # print(metric)\n",
    "        # print(f'Max: {max} iter: {scores[metric].index(max) + 1}')\n",
    "        # print(f'Min: {min} iter: {scores[metric].index(min) + 1}')\n",
    "        # print(f'Avg: {avg}')\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| words         | euclidean                         | cosine                            | jaccard                               |\n",
      "+===============+===================================+===================================+=======================================+\n",
      "| all words     | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.34801733362930337 iter: 24 | Max: 0.4258467650301553 iter: 39  | Max: 0.02675954833593846 iter: 20     |\n",
      "|               | Min: 0.19360643944592862 iter: 21 | Min: 0.26781968314970844 iter: 25 | Min: 0.01209177599427773 iter: 15     |\n",
      "|               | Avg: 0.24554375725840605          | Avg: 0.34414248966014926          | Avg: 0.01745707028774801              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.17757658067299686 iter: 24 | Max: 0.2231269348101184 iter: 39  | Max: 0.0019016253697572514 iter: 36   |\n",
      "|               | Min: 0.06009175740601231 iter: 21 | Min: 0.1368408848655201 iter: 45  | Min: -4.6964195074710034e-05 iter: 27 |\n",
      "|               | Avg: 0.09770295327782741          | Avg: 0.16649409750564717          | Avg: 0.0007523049787573073            |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.3480173336293033 iter: 24  | Max: 0.4258467650301553 iter: 39  | Max: 0.02675954833593846 iter: 20     |\n",
      "|               | Min: 0.19360643944592862 iter: 21 | Min: 0.26781968314970844 iter: 5  | Min: 0.012091775994277727 iter: 15    |\n",
      "|               | Avg: 0.24554375725840608          | Avg: 0.34414248966014926          | Avg: 0.01745707028774801              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.2894929979075682 iter: 24  | Max: 0.3841909838611012 iter: 39  | Max: 0.015575069787552978 iter: 20    |\n",
      "|               | Min: 0.13811632565954546 iter: 21 | Min: 0.23229729629832385 iter: 25 | Min: 0.0071843186251612816 iter: 30   |\n",
      "|               | Avg: 0.18108947094887243          | Avg: 0.2846998421699277           | Avg: 0.011097238326280045             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.28328446266621 iter: 13    | Max: 0.3653923361382828 iter: 4   | Max: 0.01889322311789746 iter: 4      |\n",
      "|               | Min: 0.2589352317275992 iter: 11  | Min: 0.3511062661663994 iter: 22  | Min: 0.009700439420666689 iter: 12    |\n",
      "|               | Avg: 0.2714479068918542           | Avg: 0.3629447710399956           | Avg: 0.016475311416286508             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.11549423594829983 iter: 13 | Max: 0.14362081320795675 iter: 14 | Max: 0.0018409251334223977 iter: 1    |\n",
      "|               | Min: 0.0882386003798622 iter: 3   | Min: 0.12363778652176341 iter: 39 | Min: 0.0004383476247532041 iter: 39   |\n",
      "|               | Avg: 0.10082615275434359          | Avg: 0.13983394268926883          | Avg: 0.001512168589311713             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.28328446266621 iter: 13    | Max: 0.3653923361382828 iter: 4   | Max: 0.01889322311789746 iter: 4      |\n",
      "|               | Min: 0.2589352317275992 iter: 11  | Min: 0.35110626616639945 iter: 22 | Min: 0.009700439420666689 iter: 12    |\n",
      "|               | Avg: 0.2714479068918542           | Avg: 0.36294477103999556          | Avg: 0.016475311416286508             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.2302367762114457 iter: 13  | Max: 0.3151478474024994 iter: 4   | Max: 0.01356607438792033 iter: 4      |\n",
      "|               | Min: 0.20538760129971365 iter: 11 | Min: 0.29775947926307456 iter: 22 | Min: 0.007140630195608888 iter: 12    |\n",
      "|               | Avg: 0.2182911514280875           | Avg: 0.3120840399190715           | Avg: 0.011859642976672906             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.24589750913590275 iter: 9  | Max: 0.2961980288884277 iter: 34  | Max: 0.020885828419637122 iter: 8     |\n",
      "|               | Min: 0.22991116147859195 iter: 14 | Min: 0.29123686987813013 iter: 14 | Min: 0.009811859878516705 iter: 31    |\n",
      "|               | Avg: 0.23597961613865856          | Avg: 0.2944307470153253           | Avg: 0.01853148665398898              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.1122084309189603 iter: 36  | Max: 0.11158588959467838 iter: 50 | Max: 0.002141988260230932 iter: 18    |\n",
      "|               | Min: 0.06733836396377733 iter: 14 | Min: 0.10860491239742555 iter: 14 | Min: 0.0015919975293593408 iter: 23   |\n",
      "|               | Avg: 0.07264729221215914          | Avg: 0.11018518662757469          | Avg: 0.001712682817105771             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.24589750913590278 iter: 9  | Max: 0.2961980288884278 iter: 34  | Max: 0.02088582841963712 iter: 8      |\n",
      "|               | Min: 0.22991116147859195 iter: 14 | Min: 0.29123686987813013 iter: 14 | Min: 0.009811859878516705 iter: 31    |\n",
      "|               | Avg: 0.23597961613865856          | Avg: 0.2944307470153253           | Avg: 0.01853148665398898              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.19483956056502444 iter: 9  | Max: 0.25708609369232466 iter: 34 | Max: 0.015289113322683942 iter: 8     |\n",
      "|               | Min: 0.1799130805527889 iter: 14  | Min: 0.25255629797497714 iter: 14 | Min: 0.007099962031248557 iter: 31    |\n",
      "|               | Avg: 0.18579543783877142          | Avg: 0.2555630755861784           | Avg: 0.013598048719033277             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    result = []\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        result.append('\\n')\n",
    "        result.append(linkage)\n",
    "        result.append('---------')\n",
    "        # print(linkage)\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            result.append(f\"{metric.__name__}: {score}\")\n",
    "            # print(f\"{metric.__name__}: \", score)\n",
    "\n",
    "        # plt.figure(figsize=[12, 12])\n",
    "        # plt.subplot(4, 1, linkages.index(linkage) + 1)\n",
    "        # children = agg_clustering.children_\n",
    "        # distance = np.arange(children.shape[0])\n",
    "        # num_of_observations = np.arange(2, children.shape[0] + 2)\n",
    "        # linkage_matrix = np.column_stack([children, distance, num_of_observations]).astype(float)\n",
    "        # dendrogram(linkage_matrix)\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "    # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              | jaccard                                             |\n",
      "+===============+=====================================================+=====================================================+=====================================================+\n",
      "| all words     | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.04725060943365263   | normalized_mutual_info_score: 0.008831547134239563  | normalized_mutual_info_score: 0.01472448095701408   |\n",
      "|               | adjusted_rand_score: 0.007549427520518734           | adjusted_rand_score: 5.7817664569131224e-05         | adjusted_rand_score: 0.0003724339207441116          |\n",
      "|               | v_measure_score: 0.04725060943365263                | v_measure_score: 0.008831547134239563               | v_measure_score: 0.01472448095701408                |\n",
      "|               | homogeneity_score: 0.03383487736556298              | homogeneity_score: 0.004602745814730743             | homogeneity_score: 0.008399099771571467             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0047969564675778    | normalized_mutual_info_score: 0.003993679502844827  |\n",
      "|               | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: 2.701397906364727e-05          | adjusted_rand_score: -2.5490794457884324e-05        |\n",
      "|               | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0047969564675778                 | v_measure_score: 0.003993679502844828               |\n",
      "|               | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0026614197327504167            | homogeneity_score: 0.0026675279905085166            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015534618574405388 | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0015403391986577846 |\n",
      "|               | adjusted_rand_score: 1.8068729162975107e-05         | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 6.089773164339867e-06          |\n",
      "|               | v_measure_score: 0.0015534618574405388              | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0015403391986577848              |\n",
      "|               | homogeneity_score: 0.0007807325812314995            | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0007741374484221495            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.01831853084080884   | normalized_mutual_info_score: 0.006366727831309798  | normalized_mutual_info_score: 0.0015894742838258105 |\n",
      "|               | adjusted_rand_score: 0.008411222447632231           | adjusted_rand_score: 7.719603901749114e-05          | adjusted_rand_score: -7.842002425468372e-05         |\n",
      "|               | v_measure_score: 0.018318530840808842               | v_measure_score: 0.006366727831309799               | v_measure_score: 0.0015894742838258103              |\n",
      "|               | homogeneity_score: 0.015471893074930836             | homogeneity_score: 0.0032695952516356144            | homogeneity_score: 0.0008739218300268483            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.003703888994630229  | normalized_mutual_info_score: 0.0032084914918756686 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 9.724670958960306e-05          | adjusted_rand_score: -8.089831905464098e-05         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.003703888994630229               | v_measure_score: 0.0032084914918756686              |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0021085020285326983            | homogeneity_score: 0.002158072251449761             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.001515947640756944  |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.6458849891914702e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.001515947640756944               |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0007618788378428358            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.03811274788063921   | normalized_mutual_info_score: 0.00616862369455978   | normalized_mutual_info_score: 0.004731372035176364  |\n",
      "|               | adjusted_rand_score: 0.016760265434487467           | adjusted_rand_score: 0.0001153508605749179          | adjusted_rand_score: 0.000282176214795113           |\n",
      "|               | v_measure_score: 0.03811274788063921                | v_measure_score: 0.00616862369455978                | v_measure_score: 0.004731372035176364               |\n",
      "|               | homogeneity_score: 0.03276379838309142              | homogeneity_score: 0.003160809366210558             | homogeneity_score: 0.0026780321862442543            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0033100386221916003 | normalized_mutual_info_score: 0.0031770647552697654 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 0.00011064018907785747         | adjusted_rand_score: 0.00015327123219592865         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0033100386221916003              | v_measure_score: 0.003177064755269765               |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0018971190800007747            | homogeneity_score: 0.002134969649417817             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0015212189806090425 |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.1526338598359016e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0015212189806090425              |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.000764528086518988             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
