{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.autos', 'sci.med',  'talk.politics.mideast']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_adj_nouns = vectorizer.fit_transform(lemm_texts_nouns_adj)\n",
    "vectors_nouns = vectorizer.fit_transform(lemm_texts_nouns)\n",
    "\n",
    "euclidean_distance_matrix = euclidean_distances(vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(vectors_adj_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(vectors_nouns)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(vectors_adj_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(vectors_nouns)\n",
    "\n",
    "jaccard_similarity_matrix = DistanceMetric.get_metric('jaccard').pairwise(vectors)\n",
    "jaccard_similarity_matrix_adj_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_adj_nouns)\n",
    "jaccard_similarity_matrix_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix, jaccard_similarity_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns, jaccard_similarity_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns, jaccard_similarity_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters):\n",
    "    scores = {}\n",
    "    result = []\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        clusters = KMeans(n_clusters=n_clusters, n_init=10, random_state=i)\n",
    "        clusters.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "\n",
    "    for metric in scores:\n",
    "        max = np.max(scores[metric])\n",
    "        min = np.min(scores[metric])\n",
    "        avg = np.mean(scores[metric])\n",
    "\n",
    "        result.append(f'{metric}\\nMax: {max} iter: {scores[metric].index(max) + 1}\\nMin: {min} iter: {scores[metric].index(min) + 1}\\nAvg: {avg}\\n')\n",
    "        # print(metric)\n",
    "        # print(f'Max: {max} iter: {scores[metric].index(max) + 1}')\n",
    "        # print(f'Min: {min} iter: {scores[metric].index(min) + 1}')\n",
    "        # print(f'Avg: {avg}')\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| words         | euclidean                         | cosine                            | jaccard                               |\n",
      "+===============+===================================+===================================+=======================================+\n",
      "| all words     | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.34801733362930337 iter: 24 | Max: 0.4258467650301553 iter: 39  | Max: 0.02675954833593846 iter: 20     |\n",
      "|               | Min: 0.19360643944592862 iter: 21 | Min: 0.26781968314970844 iter: 25 | Min: 0.01209177599427773 iter: 15     |\n",
      "|               | Avg: 0.24554375725840605          | Avg: 0.34414248966014926          | Avg: 0.01745707028774801              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.17757658067299686 iter: 24 | Max: 0.2231269348101184 iter: 39  | Max: 0.0019016253697572514 iter: 36   |\n",
      "|               | Min: 0.06009175740601231 iter: 21 | Min: 0.1368408848655201 iter: 45  | Min: -4.6964195074710034e-05 iter: 27 |\n",
      "|               | Avg: 0.09770295327782741          | Avg: 0.16649409750564717          | Avg: 0.0007523049787573073            |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.3480173336293033 iter: 24  | Max: 0.4258467650301553 iter: 39  | Max: 0.02675954833593846 iter: 20     |\n",
      "|               | Min: 0.19360643944592862 iter: 21 | Min: 0.26781968314970844 iter: 5  | Min: 0.012091775994277727 iter: 15    |\n",
      "|               | Avg: 0.24554375725840608          | Avg: 0.34414248966014926          | Avg: 0.01745707028774801              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.2894929979075682 iter: 24  | Max: 0.3841909838611012 iter: 39  | Max: 0.015575069787552978 iter: 20    |\n",
      "|               | Min: 0.13811632565954546 iter: 21 | Min: 0.23229729629832385 iter: 25 | Min: 0.0071843186251612816 iter: 30   |\n",
      "|               | Avg: 0.18108947094887243          | Avg: 0.2846998421699277           | Avg: 0.011097238326280045             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.28328446266621 iter: 13    | Max: 0.3653923361382828 iter: 4   | Max: 0.01889322311789746 iter: 4      |\n",
      "|               | Min: 0.2589352317275992 iter: 11  | Min: 0.3511062661663994 iter: 22  | Min: 0.009700439420666689 iter: 12    |\n",
      "|               | Avg: 0.2714479068918542           | Avg: 0.3629447710399956           | Avg: 0.016475311416286508             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.11549423594829983 iter: 13 | Max: 0.14362081320795675 iter: 14 | Max: 0.0018409251334223977 iter: 1    |\n",
      "|               | Min: 0.0882386003798622 iter: 3   | Min: 0.12363778652176341 iter: 39 | Min: 0.0004383476247532041 iter: 39   |\n",
      "|               | Avg: 0.10082615275434359          | Avg: 0.13983394268926883          | Avg: 0.001512168589311713             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.28328446266621 iter: 13    | Max: 0.3653923361382828 iter: 4   | Max: 0.01889322311789746 iter: 4      |\n",
      "|               | Min: 0.2589352317275992 iter: 11  | Min: 0.35110626616639945 iter: 22 | Min: 0.009700439420666689 iter: 12    |\n",
      "|               | Avg: 0.2714479068918542           | Avg: 0.36294477103999556          | Avg: 0.016475311416286508             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.2302367762114457 iter: 13  | Max: 0.3151478474024994 iter: 4   | Max: 0.01356607438792033 iter: 4      |\n",
      "|               | Min: 0.20538760129971365 iter: 11 | Min: 0.29775947926307456 iter: 22 | Min: 0.007140630195608888 iter: 12    |\n",
      "|               | Avg: 0.2182911514280875           | Avg: 0.3120840399190715           | Avg: 0.011859642976672906             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score      | normalized_mutual_info_score      | normalized_mutual_info_score          |\n",
      "|               | Max: 0.24589750913590275 iter: 9  | Max: 0.2961980288884277 iter: 34  | Max: 0.020885828419637122 iter: 8     |\n",
      "|               | Min: 0.22991116147859195 iter: 14 | Min: 0.29123686987813013 iter: 14 | Min: 0.009811859878516705 iter: 31    |\n",
      "|               | Avg: 0.23597961613865856          | Avg: 0.2944307470153253           | Avg: 0.01853148665398898              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | adjusted_rand_score               | adjusted_rand_score               | adjusted_rand_score                   |\n",
      "|               | Max: 0.1122084309189603 iter: 36  | Max: 0.11158588959467838 iter: 50 | Max: 0.002141988260230932 iter: 18    |\n",
      "|               | Min: 0.06733836396377733 iter: 14 | Min: 0.10860491239742555 iter: 14 | Min: 0.0015919975293593408 iter: 23   |\n",
      "|               | Avg: 0.07264729221215914          | Avg: 0.11018518662757469          | Avg: 0.001712682817105771             |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | v_measure_score                   | v_measure_score                   | v_measure_score                       |\n",
      "|               | Max: 0.24589750913590278 iter: 9  | Max: 0.2961980288884278 iter: 34  | Max: 0.02088582841963712 iter: 8      |\n",
      "|               | Min: 0.22991116147859195 iter: 14 | Min: 0.29123686987813013 iter: 14 | Min: 0.009811859878516705 iter: 31    |\n",
      "|               | Avg: 0.23597961613865856          | Avg: 0.2944307470153253           | Avg: 0.01853148665398898              |\n",
      "|               |                                   |                                   |                                       |\n",
      "|               | homogeneity_score                 | homogeneity_score                 | homogeneity_score                     |\n",
      "|               | Max: 0.19483956056502444 iter: 9  | Max: 0.25708609369232466 iter: 34 | Max: 0.015289113322683942 iter: 8     |\n",
      "|               | Min: 0.1799130805527889 iter: 14  | Min: 0.25255629797497714 iter: 14 | Min: 0.007099962031248557 iter: 31    |\n",
      "|               | Avg: 0.18579543783877142          | Avg: 0.2555630755861784           | Avg: 0.013598048719033277             |\n",
      "+---------------+-----------------------------------+-----------------------------------+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    result = []\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        result.append('\\n')\n",
    "        result.append(linkage)\n",
    "        result.append('---------')\n",
    "        # print(linkage)\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            result.append(f\"{metric.__name__}: {score}\")\n",
    "            # print(f\"{metric.__name__}: \", score)\n",
    "\n",
    "        # plt.figure(figsize=[12, 12])\n",
    "        # plt.subplot(4, 1, linkages.index(linkage) + 1)\n",
    "        # children = agg_clustering.children_\n",
    "        # distance = np.arange(children.shape[0])\n",
    "        # num_of_observations = np.arange(2, children.shape[0] + 2)\n",
    "        # linkage_matrix = np.column_stack([children, distance, num_of_observations]).astype(float)\n",
    "        # dendrogram(linkage_matrix)\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "    # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              | jaccard                                             |\n",
      "+===============+=====================================================+=====================================================+=====================================================+\n",
      "| all words     | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.04725060943365263   | normalized_mutual_info_score: 0.008831547134239563  | normalized_mutual_info_score: 0.01472448095701408   |\n",
      "|               | adjusted_rand_score: 0.007549427520518734           | adjusted_rand_score: 5.7817664569131224e-05         | adjusted_rand_score: 0.0003724339207441116          |\n",
      "|               | v_measure_score: 0.04725060943365263                | v_measure_score: 0.008831547134239563               | v_measure_score: 0.01472448095701408                |\n",
      "|               | homogeneity_score: 0.03383487736556298              | homogeneity_score: 0.004602745814730743             | homogeneity_score: 0.008399099771571467             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0047969564675778    | normalized_mutual_info_score: 0.003993679502844827  |\n",
      "|               | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: 2.701397906364727e-05          | adjusted_rand_score: -2.5490794457884324e-05        |\n",
      "|               | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0047969564675778                 | v_measure_score: 0.003993679502844828               |\n",
      "|               | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0026614197327504167            | homogeneity_score: 0.0026675279905085166            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015534618574405388 | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0015403391986577846 |\n",
      "|               | adjusted_rand_score: 1.8068729162975107e-05         | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 6.089773164339867e-06          |\n",
      "|               | v_measure_score: 0.0015534618574405388              | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0015403391986577848              |\n",
      "|               | homogeneity_score: 0.0007807325812314995            | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0007741374484221495            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.01831853084080884   | normalized_mutual_info_score: 0.006366727831309798  | normalized_mutual_info_score: 0.0015894742838258105 |\n",
      "|               | adjusted_rand_score: 0.008411222447632231           | adjusted_rand_score: 7.719603901749114e-05          | adjusted_rand_score: -7.842002425468372e-05         |\n",
      "|               | v_measure_score: 0.018318530840808842               | v_measure_score: 0.006366727831309799               | v_measure_score: 0.0015894742838258103              |\n",
      "|               | homogeneity_score: 0.015471893074930836             | homogeneity_score: 0.0032695952516356144            | homogeneity_score: 0.0008739218300268483            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.003703888994630229  | normalized_mutual_info_score: 0.0032084914918756686 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 9.724670958960306e-05          | adjusted_rand_score: -8.089831905464098e-05         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.003703888994630229               | v_measure_score: 0.0032084914918756686              |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0021085020285326983            | homogeneity_score: 0.002158072251449761             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.001515947640756944  |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.6458849891914702e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.001515947640756944               |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0007618788378428358            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.03811274788063921   | normalized_mutual_info_score: 0.00616862369455978   | normalized_mutual_info_score: 0.004731372035176364  |\n",
      "|               | adjusted_rand_score: 0.016760265434487467           | adjusted_rand_score: 0.0001153508605749179          | adjusted_rand_score: 0.000282176214795113           |\n",
      "|               | v_measure_score: 0.03811274788063921                | v_measure_score: 0.00616862369455978                | v_measure_score: 0.004731372035176364               |\n",
      "|               | homogeneity_score: 0.03276379838309142              | homogeneity_score: 0.003160809366210558             | homogeneity_score: 0.0026780321862442543            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0033100386221916003 | normalized_mutual_info_score: 0.0031770647552697654 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 0.00011064018907785747         | adjusted_rand_score: 0.00015327123219592865         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0033100386221916003              | v_measure_score: 0.003177064755269765               |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0018971190800007747            | homogeneity_score: 0.002134969649417817             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0015212189806090425 |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.1526338598359016e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0015212189806090425              |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.000764528086518988             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_adj_nouns = vectorizer.fit_transform(lemm_texts_nouns_adj)\n",
    "vectors_nouns = vectorizer.fit_transform(lemm_texts_nouns)\n",
    "\n",
    "euclidean_distance_matrix = euclidean_distances(vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(vectors_adj_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(vectors_nouns)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(vectors_adj_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(vectors_nouns)\n",
    "\n",
    "jaccard_similarity_matrix = DistanceMetric.get_metric('jaccard').pairwise(vectors)\n",
    "jaccard_similarity_matrix_adj_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_adj_nouns)\n",
    "jaccard_similarity_matrix_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix, jaccard_similarity_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns, jaccard_similarity_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns, jaccard_similarity_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| words         | euclidean                            | cosine                              | jaccard                              |\n",
      "+===============+======================================+=====================================+======================================+\n",
      "| all words     | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.00989720425486164 iter: 27    | Max: 0.06705030887874189 iter: 16   | Max: 0.0024613566626412752 iter: 34  |\n",
      "|               | Min: 0.00867397313342348 iter: 44    | Min: 0.06589595692174573 iter: 30   | Min: 0.0006243085014123848 iter: 26  |\n",
      "|               | Avg: 0.009237487871880801            | Avg: 0.06650649272880205            | Avg: 0.0009126573425607214           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.004704129796147561 iter: 27   | Max: 0.008630883496648617 iter: 16  | Max: 0.0018278135815092765 iter: 16  |\n",
      "|               | Min: 0.003732048748137828 iter: 44   | Min: 0.007756438538600965 iter: 1   | Min: 0.0003506146941817634 iter: 34  |\n",
      "|               | Avg: 0.004108176295301857            | Avg: 0.008170286920124748           | Avg: 0.0014210634854765719           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.00989720425486164 iter: 27    | Max: 0.06705030887874189 iter: 16   | Max: 0.0024613566626412752 iter: 34  |\n",
      "|               | Min: 0.00867397313342348 iter: 44    | Min: 0.06589595692174573 iter: 30   | Min: 0.0006243085014123848 iter: 26  |\n",
      "|               | Avg: 0.009237487871880801            | Avg: 0.06650649272880205            | Avg: 0.0009126573425607214           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.00826297426681117 iter: 27    | Max: 0.05886385664527416 iter: 16   | Max: 0.001529892311851259 iter: 34   |\n",
      "|               | Min: 0.00724058882580948 iter: 44    | Min: 0.05761572225092139 iter: 30   | Min: 0.00041562583820666817 iter: 26 |\n",
      "|               | Avg: 0.007707741380639321            | Avg: 0.05821246249389416            | Avg: 0.0006062721690794969           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.00965331190974325 iter: 23    | Max: 0.0898939751319832 iter: 21    | Max: 0.0009792645190992368 iter: 14  |\n",
      "|               | Min: 0.008765948647461662 iter: 38   | Min: 0.05606041387688407 iter: 31   | Min: 0.000763872115459146 iter: 1    |\n",
      "|               | Avg: 0.009232484140775581            | Avg: 0.05969590182747653            | Avg: 0.0008292563375671927           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.0026760376413390774 iter: 23  | Max: 0.028233394276724763 iter: 21  | Max: 0.0006842656016879369 iter: 32  |\n",
      "|               | Min: 0.002023452490170424 iter: 38   | Min: 0.0046916331430225024 iter: 31 | Min: 0.00044523980286530635 iter: 1  |\n",
      "|               | Avg: 0.0022839416838921645           | Avg: 0.006480334629779371           | Avg: 0.0005404916646942859           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.00965331190974325 iter: 23    | Max: 0.08989397513198319 iter: 21   | Max: 0.0009792645190992368 iter: 14  |\n",
      "|               | Min: 0.00876594864746166 iter: 38    | Min: 0.056060413876884076 iter: 31  | Min: 0.000763872115459146 iter: 1    |\n",
      "|               | Avg: 0.009232484140775581            | Avg: 0.05969590182747653            | Avg: 0.0008292563375671927           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.00804883504938617 iter: 23    | Max: 0.07826375419193418 iter: 21   | Max: 0.0007019757286300856 iter: 14  |\n",
      "|               | Min: 0.0073016782922253895 iter: 38  | Min: 0.04827873827074757 iter: 31   | Min: 0.0005513163338560846 iter: 1   |\n",
      "|               | Avg: 0.007688538893868752            | Avg: 0.051532939796837256           | Avg: 0.0005948785073507602           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.005894490336502347 iter: 16   | Max: 0.06917376697580999 iter: 48   | Max: 0.001891746795442741 iter: 39   |\n",
      "|               | Min: 0.004223612710640147 iter: 2    | Min: 0.06718552182376501 iter: 7    | Min: 0.0014945191047373368 iter: 13  |\n",
      "|               | Avg: 0.005472682138522197            | Avg: 0.06739769480531951            | Avg: 0.0017184885339054654           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.0007351645977886789 iter: 16  | Max: 0.01378145523393777 iter: 48   | Max: 0.0010536684126072453 iter: 39  |\n",
      "|               | Min: -3.0583477695435496e-05 iter: 2 | Min: 0.013045446051232203 iter: 25  | Min: 0.0007943082094913861 iter: 13  |\n",
      "|               | Avg: 0.0004950908910843203           | Avg: 0.013165680231496425           | Avg: 0.0009212451235968242           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.0058944903365023464 iter: 16  | Max: 0.06917376697581 iter: 48      | Max: 0.001891746795442741 iter: 39   |\n",
      "|               | Min: 0.004223612710640147 iter: 2    | Min: 0.06718552182376501 iter: 7    | Min: 0.0014945191047373368 iter: 13  |\n",
      "|               | Avg: 0.005472682138522197            | Avg: 0.06739769480531951            | Avg: 0.0017184885339054654           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.004962963734849487 iter: 16   | Max: 0.06027994029935692 iter: 48   | Max: 0.0013740305236002212 iter: 39  |\n",
      "|               | Min: 0.003570435237151268 iter: 2    | Min: 0.05865823606300129 iter: 7    | Min: 0.0010882842348435106 iter: 13  |\n",
      "|               | Avg: 0.004610743562689432            | Avg: 0.05883699697657002            | Avg: 0.0012505079356201132           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              | jaccard                                              |\n",
      "+===============+=====================================================+=====================================================+======================================================+\n",
      "| all words     | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.01757673451070667   | normalized_mutual_info_score: 0.023622156850907686  | normalized_mutual_info_score: 0.0027278125516680633  |\n",
      "|               | adjusted_rand_score: 0.0021760001055478474          | adjusted_rand_score: 0.001837123289824085           | adjusted_rand_score: -8.689118235675604e-05          |\n",
      "|               | v_measure_score: 0.01757673451070667                | v_measure_score: 0.023622156850907686               | v_measure_score: 0.002727812551668063                |\n",
      "|               | homogeneity_score: 0.011062998099638023             | homogeneity_score: 0.012731992686354797             | homogeneity_score: 0.0013827301538634417             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.001553853019830139  | normalized_mutual_info_score: 0.0008054224458444695 | normalized_mutual_info_score: 0.0010870405332491571  |\n",
      "|               | adjusted_rand_score: 4.060126104054516e-05          | adjusted_rand_score: 0.00021036812992633776         | adjusted_rand_score: -0.0007299558796045252          |\n",
      "|               | v_measure_score: 0.001553853019830139               | v_measure_score: 0.0008054224458444695              | v_measure_score: 0.001087040533249157                |\n",
      "|               | homogeneity_score: 0.0007817220373084805            | homogeneity_score: 0.00044966569252644805           | homogeneity_score: 0.0007408559822426252             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0014210558150619882 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0014210558150619882  |\n",
      "|               | adjusted_rand_score: -0.00010279161457392863        | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.00010279161457392863         |\n",
      "|               | v_measure_score: 0.0014210558150619884              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0014210558150619884               |\n",
      "|               | homogeneity_score: 0.0007149135939516061            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007149135939516061             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.005672998188794483  | normalized_mutual_info_score: 0.011515808410836041  | normalized_mutual_info_score: 0.004982305225326041   |\n",
      "|               | adjusted_rand_score: 0.0025244250833076107          | adjusted_rand_score: 0.0011864098114761777          | adjusted_rand_score: 0.00034206380158647627          |\n",
      "|               | v_measure_score: 0.005672998188794484               | v_measure_score: 0.011515808410836041               | v_measure_score: 0.004982305225326041                |\n",
      "|               | homogeneity_score: 0.003320145167906631             | homogeneity_score: 0.005968756260198418             | homogeneity_score: 0.002542821519466101              |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0008799911685924768 | normalized_mutual_info_score: 0.0001910933188094951  |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.0003053617512556256         | adjusted_rand_score: -0.00012027845969144645         |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0008799911685924768              | v_measure_score: 0.00019109331880949506              |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0005078437955248916            | homogeneity_score: 0.00013441492234374055            |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0015762914621453169  |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 6.683166511636353e-05           |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0015762914621453169               |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007930105083651363             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.01501136042713871   | normalized_mutual_info_score: 0.007462845128208882  | normalized_mutual_info_score: 0.004982305225326041   |\n",
      "|               | adjusted_rand_score: 0.010264379914473782           | adjusted_rand_score: 0.0006658021000663491          | adjusted_rand_score: 0.00034206380158647627          |\n",
      "|               | v_measure_score: 0.01501136042713871                | v_measure_score: 0.007462845128208882               | v_measure_score: 0.004982305225326041                |\n",
      "|               | homogeneity_score: 0.012866792481229372             | homogeneity_score: 0.003832203952715021             | homogeneity_score: 0.002542821519466101              |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0011001374298359229 | normalized_mutual_info_score: 0.00033462651606586043 |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.00044992845219088667        | adjusted_rand_score: -0.0006545312868381451          |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.001100137429835923               | v_measure_score: 0.00033462651606586043              |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0006409149693020832            | homogeneity_score: 0.0002355105636743708             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0014210558150619882 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.001688279862522615   |\n",
      "|               | adjusted_rand_score: -0.00010279161457392863        | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 0.0001857428302600735           |\n",
      "|               | v_measure_score: 0.0014210558150619884              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.001688279862522615                |\n",
      "|               | homogeneity_score: 0.0007149135939516061            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0008493503290435613             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
