{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.autos', 'sci.med',  'talk.politics.mideast']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]\n",
    "\n",
    "# lemmatized_collection_POS = [[{token.lemma_.lower(): token.pos_} for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT'] for text in news_groups.data]\n",
    "\n",
    "# print(lemmatized_collection)\n",
    "# print(lemmatized_collection_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(lemm_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_adj_nouns = vectorizer.fit_transform(lemm_texts_nouns_adj)\n",
    "vectors_nouns = vectorizer.fit_transform(lemm_texts_nouns)\n",
    "\n",
    "euclidean_distance_matrix = euclidean_distances(vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(vectors_adj_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(vectors_nouns)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(vectors_adj_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(vectors_nouns)\n",
    "\n",
    "jaccard_similarity_matrix = DistanceMetric.get_metric('jaccard').pairwise(vectors)\n",
    "jaccard_similarity_matrix_adj_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_adj_nouns)\n",
    "jaccard_similarity_matrix_nouns = DistanceMetric.get_metric('jaccard').pairwise(vectors_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix, jaccard_similarity_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns, jaccard_similarity_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns, jaccard_similarity_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters):\n",
    "    scores = {}\n",
    "    result = []\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        clusters = KMeans(n_clusters=n_clusters, n_init=10)\n",
    "        clusters.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "\n",
    "    for metric in scores:\n",
    "        max = np.max(scores[metric])\n",
    "        min = np.min(scores[metric])\n",
    "        avg = np.mean(scores[metric])\n",
    "\n",
    "        result.append(f'{metric}\\nMax: {max} iter: {scores[metric].index(max) + 1}\\nMin: {min} iter: {scores[metric].index(min) + 1}\\nAvg: {avg}\\n')\n",
    "        # print(metric)\n",
    "        # print(f'Max: {max} iter: {scores[metric].index(max) + 1}')\n",
    "        # print(f'Min: {min} iter: {scores[metric].index(min) + 1}')\n",
    "        # print(f'Avg: {avg}')\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "| words         | euclidean                          | cosine                            | jaccard                              |\n",
      "+===============+====================================+===================================+======================================+\n",
      "| all words     | normalized_mutual_info_score       | normalized_mutual_info_score      | normalized_mutual_info_score         |\n",
      "|               | Max: 0.35308510749159355 iter: 30  | Max: 0.42198909471231216 iter: 5  | Max: 0.020543863504170163 iter: 8    |\n",
      "|               | Min: 0.19247054307228872 iter: 27  | Min: 0.2676083036717975 iter: 21  | Min: 0.011883379526465019 iter: 37   |\n",
      "|               | Avg: 0.24373422059537667           | Avg: 0.3453079389697233           | Avg: 0.01764014041154703             |\n",
      "|               |                                    |                                   |                                      |\n",
      "|               | adjusted_rand_score                | adjusted_rand_score               | adjusted_rand_score                  |\n",
      "|               | Max: 0.18335498365766892 iter: 30  | Max: 0.21314018665160248 iter: 5  | Max: 0.0018929714577903586 iter: 3   |\n",
      "|               | Min: 0.060322418311261075 iter: 27 | Min: 0.13736723486567232 iter: 36 | Min: -4.1511599144637985e-05 iter: 9 |\n",
      "|               | Avg: 0.09668146121038688           | Avg: 0.16809162970337618          | Avg: 0.0009708534647131763           |\n",
      "|               |                                    |                                   |                                      |\n",
      "|               | v_measure_score                    | v_measure_score                   | v_measure_score                      |\n",
      "|               | Max: 0.3530851074915936 iter: 30   | Max: 0.42198909471231216 iter: 5  | Max: 0.02054386350417016 iter: 8     |\n",
      "|               | Min: 0.19247054307228872 iter: 27  | Min: 0.2676083036717975 iter: 21  | Min: 0.011883379526465019 iter: 37   |\n",
      "|               | Avg: 0.2437342205953767            | Avg: 0.34530793896972317          | Avg: 0.01764014041154703             |\n",
      "|               |                                    |                                   |                                      |\n",
      "|               | homogeneity_score                  | homogeneity_score                 | homogeneity_score                    |\n",
      "|               | Max: 0.29440666998630327 iter: 30  | Max: 0.3788803407874798 iter: 5   | Max: 0.01340836488426249 iter: 26    |\n",
      "|               | Min: 0.13737587834392243 iter: 27  | Min: 0.23188269092094663 iter: 36 | Min: 0.0073586821894988455 iter: 49  |\n",
      "|               | Avg: 0.1797173123509501            | Avg: 0.2858956189527591           | Avg: 0.01134307809813806             |\n",
      "+---------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "| adj and nouns |                                    |                                   |                                      |\n",
      "+---------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "| nouns         |                                    |                                   |                                      |\n",
      "+---------------+------------------------------------+-----------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "# for matrix in matrixes_adj_nouns:\n",
    "#     arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "# for matrix in matrixes_nouns:\n",
    "#     arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    result = []\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        result.append('\\n')\n",
    "        result.append(linkage)\n",
    "        result.append('---------')\n",
    "        # print(linkage)\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            result.append(f\"{metric.__name__}: {score}\")\n",
    "            # print(f\"{metric.__name__}: \", score)\n",
    "\n",
    "        # plt.figure(figsize=[12, 12])\n",
    "        # plt.subplot(4, 1, linkages.index(linkage) + 1)\n",
    "        # children = agg_clustering.children_\n",
    "        # distance = np.arange(children.shape[0])\n",
    "        # num_of_observations = np.arange(2, children.shape[0] + 2)\n",
    "        # linkage_matrix = np.column_stack([children, distance, num_of_observations]).astype(float)\n",
    "        # dendrogram(linkage_matrix)\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "    # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              | jaccard                                             |\n",
      "+===============+=====================================================+=====================================================+=====================================================+\n",
      "| all words     | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.04725060943365263   | normalized_mutual_info_score: 0.008831547134239563  | normalized_mutual_info_score: 0.01472448095701408   |\n",
      "|               | adjusted_rand_score: 0.007549427520518734           | adjusted_rand_score: 5.7817664569131224e-05         | adjusted_rand_score: 0.0003724339207441116          |\n",
      "|               | v_measure_score: 0.04725060943365263                | v_measure_score: 0.008831547134239563               | v_measure_score: 0.01472448095701408                |\n",
      "|               | homogeneity_score: 0.03383487736556298              | homogeneity_score: 0.004602745814730743             | homogeneity_score: 0.008399099771571467             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0047969564675778    | normalized_mutual_info_score: 0.003993679502844827  |\n",
      "|               | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: 2.701397906364727e-05          | adjusted_rand_score: -2.5490794457884324e-05        |\n",
      "|               | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0047969564675778                 | v_measure_score: 0.003993679502844828               |\n",
      "|               | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0026614197327504167            | homogeneity_score: 0.0026675279905085166            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015534618574405388 | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0015403391986577846 |\n",
      "|               | adjusted_rand_score: 1.8068729162975107e-05         | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 6.089773164339867e-06          |\n",
      "|               | v_measure_score: 0.0015534618574405388              | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0015403391986577848              |\n",
      "|               | homogeneity_score: 0.0007807325812314995            | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0007741374484221495            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.01831853084080884   | normalized_mutual_info_score: 0.006366727831309798  | normalized_mutual_info_score: 0.0015894742838258105 |\n",
      "|               | adjusted_rand_score: 0.008411222447632231           | adjusted_rand_score: 7.719603901749114e-05          | adjusted_rand_score: -7.842002425468372e-05         |\n",
      "|               | v_measure_score: 0.018318530840808842               | v_measure_score: 0.006366727831309799               | v_measure_score: 0.0015894742838258103              |\n",
      "|               | homogeneity_score: 0.015471893074930836             | homogeneity_score: 0.0032695952516356144            | homogeneity_score: 0.0008739218300268483            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.003703888994630229  | normalized_mutual_info_score: 0.0032084914918756686 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 9.724670958960306e-05          | adjusted_rand_score: -8.089831905464098e-05         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.003703888994630229               | v_measure_score: 0.0032084914918756686              |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0021085020285326983            | homogeneity_score: 0.002158072251449761             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.001515947640756944  |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.6458849891914702e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.001515947640756944               |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.0007618788378428358            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.03811274788063921   | normalized_mutual_info_score: 0.00616862369455978   | normalized_mutual_info_score: 0.004731372035176364  |\n",
      "|               | adjusted_rand_score: 0.016760265434487467           | adjusted_rand_score: 0.0001153508605749179          | adjusted_rand_score: 0.000282176214795113           |\n",
      "|               | v_measure_score: 0.03811274788063921                | v_measure_score: 0.00616862369455978                | v_measure_score: 0.004731372035176364               |\n",
      "|               | homogeneity_score: 0.03276379838309142              | homogeneity_score: 0.003160809366210558             | homogeneity_score: 0.0026780321862442543            |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | average                                             | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.0033100386221916003 | normalized_mutual_info_score: 0.0031770647552697654 |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 0.00011064018907785747         | adjusted_rand_score: 0.00015327123219592865         |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.0033100386221916003              | v_measure_score: 0.003177064755269765               |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0018971190800007747            | homogeneity_score: 0.002134969649417817             |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |                                                     |\n",
      "|               | single                                              | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015343217859366265 | normalized_mutual_info_score: 0.0015212189806090425 | normalized_mutual_info_score: 0.0015212189806090425 |\n",
      "|               | adjusted_rand_score: 4.5261740027622425e-07         | adjusted_rand_score: -1.1526338598359016e-05        | adjusted_rand_score: -1.1526338598359016e-05        |\n",
      "|               | v_measure_score: 0.0015343217859366263              | v_measure_score: 0.0015212189806090425              | v_measure_score: 0.0015212189806090425              |\n",
      "|               | homogeneity_score: 0.000771113241459086             | homogeneity_score: 0.000764528086518988             | homogeneity_score: 0.000764528086518988             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['words', 'euclidean', 'cosine', 'jaccard']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
