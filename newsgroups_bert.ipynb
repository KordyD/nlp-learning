{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dimak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"bert-base-uncased\", \n",
    "    \"roberta-base\",\n",
    "    \"distilbert-base-uncased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./20news_bert/\"\n",
    "kmeans_res_path = \"kmeans_res_20News_hard_bert.xlsx\"\n",
    "hierarchy_res_path = \"hierarchy_res_20News_hard_bert.xlsx\"\n",
    "\n",
    "categories_light = [\"comp.graphics\", \"rec.autos\", \"sci.med\",  \"talk.politics.mideast\"]\n",
    "categories_hard = [\"talk.politics.guns\", \"talk.politics.mideast\",  \"talk.politics.misc\"]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\",\n",
    "                                remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "                                categories=categories_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words ]\n",
    "    \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_by_pos(text, pos_to_keep):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    \n",
    "    filtered_tokens = [token for token, pos in tagged_tokens if pos in pos_to_keep]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(matrix, metrics, true_labels, num_clusters=2, num_iterations=5):\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        clusters = KMeans(n_clusters=num_clusters, random_state=i, n_init=10)\n",
    "\n",
    "        clusters.fit_predict(matrix)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "    kmeans_res = \"\"\n",
    "    for metric in scores:\n",
    "        kmeans_res += f\"\\n{metric} \\nMax: {np.max(scores[metric])} \\\n",
    "                                    \\nMin: {np.min(scores[metric])} \\\n",
    "                                    \\nAVG: {np.mean(scores[metric])} \\n\"\n",
    "        \n",
    "    print(kmeans_res)\n",
    "    return kmeans_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters=2):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "\n",
    "    hierarchy_res = \"\"\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        # matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        hierarchy_res += f\"\\n{linkage}\"\n",
    "\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit_predict(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            hierarchy_res += f\"\\n{metric.__name__}: {score}\"\n",
    "        \n",
    "        hierarchy_res += \"\\n\"\n",
    "    \n",
    "    print(hierarchy_res)\n",
    "    return hierarchy_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, model_name):\n",
    "    true_labels = dataset.target\n",
    "    distances = [\"euclidean\", \"cosine\"]\n",
    "    metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    kmeans_data = pd.DataFrame(columns=distances)\n",
    "    hierarchy_data = pd.DataFrame(columns=distances)\n",
    "\n",
    "    preprocessed_data = [preprocess_text(text) for text in dataset.data]\n",
    "    n = len(preprocessed_data)\n",
    "    print(n)\n",
    "\n",
    "    noun_data = [filter_text_by_pos(text, pos_to_keep=['NN', 'NNS']) for text in preprocessed_data]\n",
    "    adj_data = [filter_text_by_pos(text, pos_to_keep=['JJ', 'JJR', 'JJS']) for text in preprocessed_data]\n",
    "    noun_adj_data = [filter_text_by_pos(text, pos_to_keep=['NN', 'NNS', 'JJ', 'JJR', 'JJS']) for text in preprocessed_data]\n",
    "\n",
    "    list_of_data = {\"ALL\": preprocessed_data, \"NOUNS\": noun_data, \"ADJ\": adj_data, \"NOUNS and ADJ\": noun_adj_data}\n",
    "\n",
    "    for name, data in list_of_data.items():\n",
    "        print(\"start calculate\")\n",
    "        text_vectors = []\n",
    "\n",
    "        i = 0\n",
    "        for sentence in data:\n",
    "            tokens = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sentence_vector = model(**tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "            i+=1\n",
    "            print(str(round(i/n*100, 2)) + \"%\", end='\\r', flush=True)\n",
    "            text_vectors.append(sentence_vector.flatten())\n",
    "\n",
    "        for distance in distances:\n",
    "            if distance == \"euclidean\":\n",
    "                distance_matrix = euclidean_distances(text_vectors)\n",
    "            elif distance == \"cosine\":\n",
    "                distance_matrix = cosine_distances(text_vectors)\n",
    "\n",
    "            kmeans_data.loc[name, distance] = cluster_kmeans(distance_matrix, metrics, true_labels, num_clusters=len(dataset.target_names))\n",
    "\n",
    "            hierarchy_data.loc[name, distance] = cluster_hierarchy(distance_matrix, metrics, true_labels, num_clusters=len(dataset.target_names))\n",
    "\n",
    "    return kmeans_data, hierarchy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "1575\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0006231394604735652                                     \n",
      "Min: 0.0006231394604735652                                     \n",
      "AVG: 0.0006231394604735652 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00026658577863961856                                     \n",
      "Min: 0.00026658577863961856                                     \n",
      "AVG: 0.00026658577863961856 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0006231394604735653                                     \n",
      "Min: 0.0006231394604735652                                     \n",
      "AVG: 0.0006231394604735652 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0004936061440714385                                     \n",
      "Min: 0.0004936061440714385                                     \n",
      "AVG: 0.0004936061440714385 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0028007637830308337\n",
      "adjusted_rand_score: 0.0007701642769419312\n",
      "v_measure_score: 0.0028007637830308337\n",
      "homogeneity_score: 0.001720482961144255\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0022177178772170457\n",
      "adjusted_rand_score: -0.00020405913624125036\n",
      "v_measure_score: 0.0022177178772170457\n",
      "homogeneity_score: 0.001255806075338451\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.002230308827317539\n",
      "adjusted_rand_score: -0.0002767675595078309\n",
      "v_measure_score: 0.0022303088273175394\n",
      "homogeneity_score: 0.0012548516837222528\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0016834176497148479                                     \n",
      "Min: 0.0014330244332288818                                     \n",
      "AVG: 0.0015926577165514255 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0013710859364930129                                     \n",
      "Min: 0.0010423245333815946                                     \n",
      "AVG: 0.0012509555568958226 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0016834176497148479                                     \n",
      "Min: 0.0014330244332288818                                     \n",
      "AVG: 0.0015926577165514255 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.001318315374760691                                     \n",
      "Min: 0.0011087907568619116                                     \n",
      "AVG: 0.0012405089267536781 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.008861855472254333\n",
      "adjusted_rand_score: 0.004040417081811793\n",
      "v_measure_score: 0.008861855472254333\n",
      "homogeneity_score: 0.0061464378785867765\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0015142476067837637\n",
      "adjusted_rand_score: -0.00012590183543673868\n",
      "v_measure_score: 0.0015142476067837637\n",
      "homogeneity_score: 0.00085478902370438\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0013696426551187766\n",
      "adjusted_rand_score: 4.0074195367033494e-05\n",
      "v_measure_score: 0.0013696426551187766\n",
      "homogeneity_score: 0.0007678522109785008\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.002805965709023427                                     \n",
      "Min: 0.002805965709023427                                     \n",
      "AVG: 0.002805965709023427 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.002424822358313188                                     \n",
      "Min: 0.002424822358313188                                     \n",
      "AVG: 0.002424822358313188 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0028059657090234273                                     \n",
      "Min: 0.0028059657090234273                                     \n",
      "AVG: 0.0028059657090234273 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0023637817117413465                                     \n",
      "Min: 0.0023637817117413465                                     \n",
      "AVG: 0.0023637817117413465 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.004640923867923317\n",
      "adjusted_rand_score: 0.0031786809803334187\n",
      "v_measure_score: 0.0046409238679233165\n",
      "homogeneity_score: 0.003404029300277429\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.003072190152215242\n",
      "adjusted_rand_score: 6.861924363486147e-05\n",
      "v_measure_score: 0.003072190152215242\n",
      "homogeneity_score: 0.0017531721291477059\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0018376921619266992\n",
      "adjusted_rand_score: -8.799959770526156e-05\n",
      "v_measure_score: 0.001837692161926699\n",
      "homogeneity_score: 0.0010449975925548296\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0021871570763359366                                     \n",
      "Min: 0.0021871570763359366                                     \n",
      "AVG: 0.0021871570763359366 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00156376443945611                                     \n",
      "Min: 0.00156376443945611                                     \n",
      "AVG: 0.0015637644394561098 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0021871570763359366                                     \n",
      "Min: 0.0021871570763359366                                     \n",
      "AVG: 0.0021871570763359366 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.001808411438035569                                     \n",
      "Min: 0.001808411438035569                                     \n",
      "AVG: 0.001808411438035569 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0033251569409213995\n",
      "adjusted_rand_score: 0.0011120478380966913\n",
      "v_measure_score: 0.0033251569409214\n",
      "homogeneity_score: 0.0025764771377616252\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.003347577107216043\n",
      "adjusted_rand_score: 0.00025994267959661166\n",
      "v_measure_score: 0.003347577107216043\n",
      "homogeneity_score: 0.002107370966138368\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0025810389376197686\n",
      "adjusted_rand_score: 6.737740424806971e-05\n",
      "v_measure_score: 0.002581038937619769\n",
      "homogeneity_score: 0.001303030803869079\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.003334463418217586                                     \n",
      "Min: 0.003215113755514083                                     \n",
      "AVG: 0.0032628536205954843 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0035468742681660894                                     \n",
      "Min: 0.003472906159163458                                     \n",
      "AVG: 0.0035024934027645103 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0033344634182175866                                     \n",
      "Min: 0.0032151137555140826                                     \n",
      "AVG: 0.0032628536205954843 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.002846012858311394                                     \n",
      "Min: 0.002739501203065434                                     \n",
      "AVG: 0.002782105865163818 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0020256549212945116\n",
      "adjusted_rand_score: 0.0019574977017644685\n",
      "v_measure_score: 0.0020256549212945116\n",
      "homogeneity_score: 0.0016265172309436091\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0014206328166809382\n",
      "adjusted_rand_score: -0.0005094000628975388\n",
      "v_measure_score: 0.0014206328166809384\n",
      "homogeneity_score: 0.0008580943160499549\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0014206328166809382\n",
      "adjusted_rand_score: -0.0005094000628975388\n",
      "v_measure_score: 0.0014206328166809384\n",
      "homogeneity_score: 0.0008580943160499549\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.005278522636555029                                     \n",
      "Min: 0.005278522636555029                                     \n",
      "AVG: 0.005278522636555029 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0074609930075714035                                     \n",
      "Min: 0.0074609930075714035                                     \n",
      "AVG: 0.0074609930075714035 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.005278522636555029                                     \n",
      "Min: 0.005278522636555029                                     \n",
      "AVG: 0.005278522636555029 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.004859912577019188                                     \n",
      "Min: 0.004859912577019188                                     \n",
      "AVG: 0.004859912577019188 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.005798579063030953\n",
      "adjusted_rand_score: 0.007450060321968204\n",
      "v_measure_score: 0.005798579063030953\n",
      "homogeneity_score: 0.005636810622184148\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.001478862856927947\n",
      "adjusted_rand_score: 0.001085784516308726\n",
      "v_measure_score: 0.0014788628569279473\n",
      "homogeneity_score: 0.0010685498527942335\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.004332119074671204                                     \n",
      "Min: 0.004332119074671204                                     \n",
      "AVG: 0.004332119074671204 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.004411901261524185                                     \n",
      "Min: 0.004411901261524185                                     \n",
      "AVG: 0.004411901261524185 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.004332119074671205                                     \n",
      "Min: 0.004332119074671204                                     \n",
      "AVG: 0.004332119074671204 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0035478889735158898                                     \n",
      "Min: 0.0035478889735158898                                     \n",
      "AVG: 0.0035478889735158898 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0013256029387161386\n",
      "adjusted_rand_score: 0.00028350544574800505\n",
      "v_measure_score: 0.0013256029387161386\n",
      "homogeneity_score: 0.0009269069571610764\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.004917990272886901\n",
      "adjusted_rand_score: -0.00050530763644618\n",
      "v_measure_score: 0.0049179902728869\n",
      "homogeneity_score: 0.0030444954748794135\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0014329507385982172\n",
      "adjusted_rand_score: -0.0004682196268720984\n",
      "v_measure_score: 0.0014329507385982172\n",
      "homogeneity_score: 0.0008091649108227342\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0037043646030486504                                     \n",
      "Min: 0.00370436460304865                                     \n",
      "AVG: 0.00370436460304865 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0008539466597245423                                     \n",
      "Min: 0.0008539466597245423                                     \n",
      "AVG: 0.0008539466597245422 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.00370436460304865                                     \n",
      "Min: 0.00370436460304865                                     \n",
      "AVG: 0.00370436460304865 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.003039344219758323                                     \n",
      "Min: 0.003039344219758323                                     \n",
      "AVG: 0.003039344219758323 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.00503488929118789\n",
      "adjusted_rand_score: 0.002061016232005132\n",
      "v_measure_score: 0.0050348892911878905\n",
      "homogeneity_score: 0.004259240345843597\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.004351398674611364\n",
      "adjusted_rand_score: -0.0008544389236410224\n",
      "v_measure_score: 0.004351398674611364\n",
      "homogeneity_score: 0.0026629490221306276\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0025810389376197686\n",
      "adjusted_rand_score: 6.737740424806971e-05\n",
      "v_measure_score: 0.002581038937619769\n",
      "homogeneity_score: 0.001303030803869079\n",
      "\n",
      "+---------------+------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "|               | euclidean                                                        | cosine                                                          |\n",
      "+===============+==================================================================+=================================================================+\n",
      "| ALL           | normalized_mutual_info_score                                     | normalized_mutual_info_score                                    |\n",
      "|               | Max: 0.0006231394604735652                                       | Max: 0.0016834176497148479                                      |\n",
      "|               | Min: 0.0006231394604735652                                       | Min: 0.0014330244332288818                                      |\n",
      "|               | AVG: 0.0006231394604735652                                       | AVG: 0.0015926577165514255                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | adjusted_rand_score                                              | adjusted_rand_score                                             |\n",
      "|               | Max: 0.00026658577863961856                                      | Max: 0.0013710859364930129                                      |\n",
      "|               | Min: 0.00026658577863961856                                      | Min: 0.0010423245333815946                                      |\n",
      "|               | AVG: 0.00026658577863961856                                      | AVG: 0.0012509555568958226                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | v_measure_score                                                  | v_measure_score                                                 |\n",
      "|               | Max: 0.0006231394604735653                                       | Max: 0.0016834176497148479                                      |\n",
      "|               | Min: 0.0006231394604735652                                       | Min: 0.0014330244332288818                                      |\n",
      "|               | AVG: 0.0006231394604735652                                       | AVG: 0.0015926577165514255                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | homogeneity_score                                                | homogeneity_score                                               |\n",
      "|               | Max: 0.0004936061440714385                                       | Max: 0.001318315374760691                                       |\n",
      "|               | Min: 0.0004936061440714385                                       | Min: 0.0011087907568619116                                      |\n",
      "|               | AVG: 0.0004936061440714385                                       | AVG: 0.0012405089267536781                                      |\n",
      "+---------------+------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "| NOUNS         | normalized_mutual_info_score                                     | normalized_mutual_info_score                                    |\n",
      "|               | Max: 0.002805965709023427                                        | Max: 0.0021871570763359366                                      |\n",
      "|               | Min: 0.002805965709023427                                        | Min: 0.0021871570763359366                                      |\n",
      "|               | AVG: 0.002805965709023427                                        | AVG: 0.0021871570763359366                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | adjusted_rand_score                                              | adjusted_rand_score                                             |\n",
      "|               | Max: 0.002424822358313188                                        | Max: 0.00156376443945611                                        |\n",
      "|               | Min: 0.002424822358313188                                        | Min: 0.00156376443945611                                        |\n",
      "|               | AVG: 0.002424822358313188                                        | AVG: 0.0015637644394561098                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | v_measure_score                                                  | v_measure_score                                                 |\n",
      "|               | Max: 0.0028059657090234273                                       | Max: 0.0021871570763359366                                      |\n",
      "|               | Min: 0.0028059657090234273                                       | Min: 0.0021871570763359366                                      |\n",
      "|               | AVG: 0.0028059657090234273                                       | AVG: 0.0021871570763359366                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | homogeneity_score                                                | homogeneity_score                                               |\n",
      "|               | Max: 0.0023637817117413465                                       | Max: 0.001808411438035569                                       |\n",
      "|               | Min: 0.0023637817117413465                                       | Min: 0.001808411438035569                                       |\n",
      "|               | AVG: 0.0023637817117413465                                       | AVG: 0.001808411438035569                                       |\n",
      "+---------------+------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "| ADJ           | normalized_mutual_info_score                                     | normalized_mutual_info_score                                    |\n",
      "|               | Max: 0.003334463418217586                                        | Max: 0.005278522636555029                                       |\n",
      "|               | Min: 0.003215113755514083                                        | Min: 0.005278522636555029                                       |\n",
      "|               | AVG: 0.0032628536205954843                                       | AVG: 0.005278522636555029                                       |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | adjusted_rand_score                                              | adjusted_rand_score                                             |\n",
      "|               | Max: 0.0035468742681660894                                       | Max: 0.0074609930075714035                                      |\n",
      "|               | Min: 0.003472906159163458                                        | Min: 0.0074609930075714035                                      |\n",
      "|               | AVG: 0.0035024934027645103                                       | AVG: 0.0074609930075714035                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | v_measure_score                                                  | v_measure_score                                                 |\n",
      "|               | Max: 0.0033344634182175866                                       | Max: 0.005278522636555029                                       |\n",
      "|               | Min: 0.0032151137555140826                                       | Min: 0.005278522636555029                                       |\n",
      "|               | AVG: 0.0032628536205954843                                       | AVG: 0.005278522636555029                                       |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | homogeneity_score                                                | homogeneity_score                                               |\n",
      "|               | Max: 0.002846012858311394                                        | Max: 0.004859912577019188                                       |\n",
      "|               | Min: 0.002739501203065434                                        | Min: 0.004859912577019188                                       |\n",
      "|               | AVG: 0.002782105865163818                                        | AVG: 0.004859912577019188                                       |\n",
      "+---------------+------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "| NOUNS and ADJ | normalized_mutual_info_score                                     | normalized_mutual_info_score                                    |\n",
      "|               | Max: 0.004332119074671204                                        | Max: 0.0037043646030486504                                      |\n",
      "|               | Min: 0.004332119074671204                                        | Min: 0.00370436460304865                                        |\n",
      "|               | AVG: 0.004332119074671204                                        | AVG: 0.00370436460304865                                        |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | adjusted_rand_score                                              | adjusted_rand_score                                             |\n",
      "|               | Max: 0.004411901261524185                                        | Max: 0.0008539466597245423                                      |\n",
      "|               | Min: 0.004411901261524185                                        | Min: 0.0008539466597245423                                      |\n",
      "|               | AVG: 0.004411901261524185                                        | AVG: 0.0008539466597245422                                      |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | v_measure_score                                                  | v_measure_score                                                 |\n",
      "|               | Max: 0.004332119074671205                                        | Max: 0.00370436460304865                                        |\n",
      "|               | Min: 0.004332119074671204                                        | Min: 0.00370436460304865                                        |\n",
      "|               | AVG: 0.004332119074671204                                        | AVG: 0.00370436460304865                                        |\n",
      "|               |                                                                  |                                                                 |\n",
      "|               | homogeneity_score                                                | homogeneity_score                                               |\n",
      "|               | Max: 0.0035478889735158898                                       | Max: 0.003039344219758323                                       |\n",
      "|               | Min: 0.0035478889735158898                                       | Min: 0.003039344219758323                                       |\n",
      "|               | AVG: 0.0035478889735158898                                       | AVG: 0.003039344219758323                                       |\n",
      "+---------------+------------------------------------------------------------------+-----------------------------------------------------------------+\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "|               | euclidean                                           | cosine                                              |\n",
      "+===============+=====================================================+=====================================================+\n",
      "| ALL           | complete                                            | complete                                            |\n",
      "|               | normalized_mutual_info_score: 0.0028007637830308337 | normalized_mutual_info_score: 0.008861855472254333  |\n",
      "|               | adjusted_rand_score: 0.0007701642769419312          | adjusted_rand_score: 0.004040417081811793           |\n",
      "|               | v_measure_score: 0.0028007637830308337              | v_measure_score: 0.008861855472254333               |\n",
      "|               | homogeneity_score: 0.001720482961144255             | homogeneity_score: 0.0061464378785867765            |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | normalized_mutual_info_score: 0.0022177178772170457 | normalized_mutual_info_score: 0.0015142476067837637 |\n",
      "|               | adjusted_rand_score: -0.00020405913624125036        | adjusted_rand_score: -0.00012590183543673868        |\n",
      "|               | v_measure_score: 0.0022177178772170457              | v_measure_score: 0.0015142476067837637              |\n",
      "|               | homogeneity_score: 0.001255806075338451             | homogeneity_score: 0.00085478902370438              |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | normalized_mutual_info_score: 0.002230308827317539  | normalized_mutual_info_score: 0.0013696426551187766 |\n",
      "|               | adjusted_rand_score: -0.0002767675595078309         | adjusted_rand_score: 4.0074195367033494e-05         |\n",
      "|               | v_measure_score: 0.0022303088273175394              | v_measure_score: 0.0013696426551187766              |\n",
      "|               | homogeneity_score: 0.0012548516837222528            | homogeneity_score: 0.0007678522109785008            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| NOUNS         | complete                                            | complete                                            |\n",
      "|               | normalized_mutual_info_score: 0.004640923867923317  | normalized_mutual_info_score: 0.0033251569409213995 |\n",
      "|               | adjusted_rand_score: 0.0031786809803334187          | adjusted_rand_score: 0.0011120478380966913          |\n",
      "|               | v_measure_score: 0.0046409238679233165              | v_measure_score: 0.0033251569409214                 |\n",
      "|               | homogeneity_score: 0.003404029300277429             | homogeneity_score: 0.0025764771377616252            |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | normalized_mutual_info_score: 0.003072190152215242  | normalized_mutual_info_score: 0.003347577107216043  |\n",
      "|               | adjusted_rand_score: 6.861924363486147e-05          | adjusted_rand_score: 0.00025994267959661166         |\n",
      "|               | v_measure_score: 0.003072190152215242               | v_measure_score: 0.003347577107216043               |\n",
      "|               | homogeneity_score: 0.0017531721291477059            | homogeneity_score: 0.002107370966138368             |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | normalized_mutual_info_score: 0.0018376921619266992 | normalized_mutual_info_score: 0.0025810389376197686 |\n",
      "|               | adjusted_rand_score: -8.799959770526156e-05         | adjusted_rand_score: 6.737740424806971e-05          |\n",
      "|               | v_measure_score: 0.001837692161926699               | v_measure_score: 0.002581038937619769               |\n",
      "|               | homogeneity_score: 0.0010449975925548296            | homogeneity_score: 0.001303030803869079             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| ADJ           | complete                                            | complete                                            |\n",
      "|               | normalized_mutual_info_score: 0.0020256549212945116 | normalized_mutual_info_score: 0.005798579063030953  |\n",
      "|               | adjusted_rand_score: 0.0019574977017644685          | adjusted_rand_score: 0.007450060321968204           |\n",
      "|               | v_measure_score: 0.0020256549212945116              | v_measure_score: 0.005798579063030953               |\n",
      "|               | homogeneity_score: 0.0016265172309436091            | homogeneity_score: 0.005636810622184148             |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | normalized_mutual_info_score: 0.0014206328166809382 | normalized_mutual_info_score: 0.001478862856927947  |\n",
      "|               | adjusted_rand_score: -0.0005094000628975388         | adjusted_rand_score: 0.001085784516308726           |\n",
      "|               | v_measure_score: 0.0014206328166809384              | v_measure_score: 0.0014788628569279473              |\n",
      "|               | homogeneity_score: 0.0008580943160499549            | homogeneity_score: 0.0010685498527942335            |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | normalized_mutual_info_score: 0.0014206328166809382 | normalized_mutual_info_score: 0.0026183193292056944 |\n",
      "|               | adjusted_rand_score: -0.0005094000628975388         | adjusted_rand_score: 0.00011111680968432928         |\n",
      "|               | v_measure_score: 0.0014206328166809384              | v_measure_score: 0.0026183193292056944              |\n",
      "|               | homogeneity_score: 0.0008580943160499549            | homogeneity_score: 0.001321851712732066             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| NOUNS and ADJ | complete                                            | complete                                            |\n",
      "|               | normalized_mutual_info_score: 0.0013256029387161386 | normalized_mutual_info_score: 0.00503488929118789   |\n",
      "|               | adjusted_rand_score: 0.00028350544574800505         | adjusted_rand_score: 0.002061016232005132           |\n",
      "|               | v_measure_score: 0.0013256029387161386              | v_measure_score: 0.0050348892911878905              |\n",
      "|               | homogeneity_score: 0.0009269069571610764            | homogeneity_score: 0.004259240345843597             |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | normalized_mutual_info_score: 0.004917990272886901  | normalized_mutual_info_score: 0.004351398674611364  |\n",
      "|               | adjusted_rand_score: -0.00050530763644618           | adjusted_rand_score: -0.0008544389236410224         |\n",
      "|               | v_measure_score: 0.0049179902728869                 | v_measure_score: 0.004351398674611364               |\n",
      "|               | homogeneity_score: 0.0030444954748794135            | homogeneity_score: 0.0026629490221306276            |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | normalized_mutual_info_score: 0.0014329507385982172 | normalized_mutual_info_score: 0.0025810389376197686 |\n",
      "|               | adjusted_rand_score: -0.0004682196268720984         | adjusted_rand_score: 6.737740424806971e-05          |\n",
      "|               | v_measure_score: 0.0014329507385982172              | v_measure_score: 0.002581038937619769               |\n",
      "|               | homogeneity_score: 0.0008091649108227342            | homogeneity_score: 0.001303030803869079             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.012290568596449954                                     \n",
      "Min: 0.012290568596449954                                     \n",
      "AVG: 0.012290568596449954 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0052640264798186395                                     \n",
      "Min: 0.0052640264798186395                                     \n",
      "AVG: 0.0052640264798186395 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.012290568596449954                                     \n",
      "Min: 0.012290568596449954                                     \n",
      "AVG: 0.012290568596449954 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.009729825884754946                                     \n",
      "Min: 0.009729825884754946                                     \n",
      "AVG: 0.009729825884754946 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.010210903130514558\n",
      "adjusted_rand_score: 0.00360761619803794\n",
      "v_measure_score: 0.010210903130514558\n",
      "homogeneity_score: 0.00832018095299523\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0181382474583357\n",
      "adjusted_rand_score: 0.0048508768229639605\n",
      "v_measure_score: 0.0181382474583357\n",
      "homogeneity_score: 0.013943148357864418\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.012501798263429717                                     \n",
      "Min: 0.012501798263429717                                     \n",
      "AVG: 0.012501798263429717 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00473193289685708                                     \n",
      "Min: 0.00473193289685708                                     \n",
      "AVG: 0.00473193289685708 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.01250179826342972                                     \n",
      "Min: 0.01250179826342972                                     \n",
      "AVG: 0.01250179826342972 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.009742327039290042                                     \n",
      "Min: 0.009742327039290042                                     \n",
      "AVG: 0.009742327039290042 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.012054427571642021\n",
      "adjusted_rand_score: 0.009594680277296784\n",
      "v_measure_score: 0.012054427571642023\n",
      "homogeneity_score: 0.010675526838282637\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.001226747365504667\n",
      "adjusted_rand_score: -1.0587941748039446e-05\n",
      "v_measure_score: 0.0012267473655046672\n",
      "homogeneity_score: 0.0006889997486384844\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.006140232595915381                                     \n",
      "Min: 0.006140232595915381                                     \n",
      "AVG: 0.006140232595915381 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0020436721767025977                                     \n",
      "Min: 0.0020436721767025977                                     \n",
      "AVG: 0.0020436721767025977 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.006140232595915381                                     \n",
      "Min: 0.006140232595915381                                     \n",
      "AVG: 0.006140232595915381 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.004806759183058248                                     \n",
      "Min: 0.004806759183058248                                     \n",
      "AVG: 0.004806759183058248 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.008538800630699978\n",
      "adjusted_rand_score: -0.00017777937309409472\n",
      "v_measure_score: 0.008538800630699976\n",
      "homogeneity_score: 0.0073425068709114276\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.010973732498471826\n",
      "adjusted_rand_score: -5.097733103210504e-05\n",
      "v_measure_score: 0.010973732498471828\n",
      "homogeneity_score: 0.008381314877773821\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.007522310402967598                                     \n",
      "Min: 0.007522310402967598                                     \n",
      "AVG: 0.007522310402967597 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.002032008774006067                                     \n",
      "Min: 0.002032008774006067                                     \n",
      "AVG: 0.002032008774006067 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.007522310402967598                                     \n",
      "Min: 0.007522310402967598                                     \n",
      "AVG: 0.007522310402967597 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.005732963091317436                                     \n",
      "Min: 0.005732963091317436                                     \n",
      "AVG: 0.005732963091317436 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0011230780621108482\n",
      "adjusted_rand_score: -0.0012399180091098802\n",
      "v_measure_score: 0.001123078062110848\n",
      "homogeneity_score: 0.000988189247498646\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.001936085328955761\n",
      "adjusted_rand_score: -0.0010284169523389645\n",
      "v_measure_score: 0.001936085328955761\n",
      "homogeneity_score: 0.0012906022605251755\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.01813104780461837                                     \n",
      "Min: 0.01739556104523664                                     \n",
      "AVG: 0.017542658397112987 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.018045285868625326                                     \n",
      "Min: 0.017460265499994156                                     \n",
      "AVG: 0.01757726957372039 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.018131047804618366                                     \n",
      "Min: 0.01739556104523664                                     \n",
      "AVG: 0.017542658397112984 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.016494462462827608                                     \n",
      "Min: 0.01571833127613934                                     \n",
      "AVG: 0.01587355751347699 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0043583936793787385\n",
      "adjusted_rand_score: 0.001922100811647575\n",
      "v_measure_score: 0.0043583936793787385\n",
      "homogeneity_score: 0.003691253688262369\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.021467821419731255                                     \n",
      "Min: 0.021374167352130963                                     \n",
      "AVG: 0.021449090606211196 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.020201701794344624                                     \n",
      "Min: 0.01978738981185778                                     \n",
      "AVG: 0.020118839397847255 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.02146782141973125                                     \n",
      "Min: 0.021374167352130963                                     \n",
      "AVG: 0.021449090606211193 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.019031609460059374                                     \n",
      "Min: 0.01891106016880265                                     \n",
      "AVG: 0.019007499601808028 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.019951562308605574\n",
      "adjusted_rand_score: 0.0026002974391189522\n",
      "v_measure_score: 0.01995156230860557\n",
      "homogeneity_score: 0.01625608840320023\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.007323034960765204\n",
      "adjusted_rand_score: -0.00027428463624072896\n",
      "v_measure_score: 0.007323034960765204\n",
      "homogeneity_score: 0.003986126186497935\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "start calculate\n",
      "17.9%%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\newsgroups_bert.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(model_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     kmeans_data, hierarchy_data \u001b[39m=\u001b[39m main(newsgroups, model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(tabulate(kmeans_data, headers\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m\"\u001b[39m, tablefmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrid\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(tabulate(hierarchy_data, headers\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m\"\u001b[39m, tablefmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrid\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\newsgroups_bert.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokenizer(sentence, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     sentence_vector \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokens)\u001b[39m.\u001b[39mlast_hidden_state\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dimak/codeProjects/nltk/newsgroups_bert.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(\u001b[39mround\u001b[39m(i\u001b[39m/\u001b[39mn\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, \u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    826\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    828\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    829\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    830\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    834\u001b[0m )\n\u001b[1;32m--> 835\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    836\u001b[0m     embedding_output,\n\u001b[0;32m    837\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    838\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    839\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    840\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    841\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    842\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    843\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    844\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    845\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    848\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    513\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    514\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    515\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         output_attentions,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[0;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    525\u001b[0m         hidden_states,\n\u001b[0;32m    526\u001b[0m         attention_mask,\n\u001b[0;32m    527\u001b[0m         layer_head_mask,\n\u001b[0;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    530\u001b[0m         past_key_value,\n\u001b[0;32m    531\u001b[0m         output_attentions,\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    534\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    402\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    403\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    411\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    414\u001b[0m         hidden_states,\n\u001b[0;32m    415\u001b[0m         attention_mask,\n\u001b[0;32m    416\u001b[0m         head_mask,\n\u001b[0;32m    417\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    418\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    419\u001b[0m     )\n\u001b[0;32m    420\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    422\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    332\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    339\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 340\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    341\u001b[0m         hidden_states,\n\u001b[0;32m    342\u001b[0m         attention_mask,\n\u001b[0;32m    343\u001b[0m         head_mask,\n\u001b[0;32m    344\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    345\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    346\u001b[0m         past_key_value,\n\u001b[0;32m    347\u001b[0m         output_attentions,\n\u001b[0;32m    348\u001b[0m     )\n\u001b[0;32m    349\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    350\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:266\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    263\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n\u001b[0;32m    265\u001b[0m \u001b[39m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attention_scores, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    268\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32mc:\\Users\\dimak\\codeProjects\\nltk\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1854\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1855\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1856\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1857\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1858\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    kmeans_data, hierarchy_data = main(newsgroups, model_name)\n",
    "    print(tabulate(kmeans_data, headers=\"keys\", tablefmt=\"grid\"))\n",
    "    print(tabulate(hierarchy_data, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "    # kmeans_data.to_excel(folder + model_name + \"/\" + kmeans_res_path)\n",
    "    # hierarchy_data.to_excel(folder + model_name + \"/\" + hierarchy_res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.016379303586388297                                     \n",
      "Min: 0.016126858677298572                                     \n",
      "AVG: 0.016283374520934202 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00833174031811477                                     \n",
      "Min: 0.008205135746090613                                     \n",
      "AVG: 0.008283630580745589 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.016379303586388297                                     \n",
      "Min: 0.016126858677298572                                     \n",
      "AVG: 0.016283374520934202 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.013504783850322138                                     \n",
      "Min: 0.01328397079676317                                     \n",
      "AVG: 0.01342087488996973 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.010210903130514558\n",
      "adjusted_rand_score: 0.00360761619803794\n",
      "v_measure_score: 0.010210903130514558\n",
      "homogeneity_score: 0.00832018095299523\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0181382474583357\n",
      "adjusted_rand_score: 0.0048508768229639605\n",
      "v_measure_score: 0.0181382474583357\n",
      "homogeneity_score: 0.013943148357864418\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.011868659958296047\n",
      "adjusted_rand_score: 0.009470854613759603\n",
      "v_measure_score: 0.011868659958296047\n",
      "homogeneity_score: 0.009940041426811555\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.012290568596449954                                     \n",
      "Min: 0.012290568596449954                                     \n",
      "AVG: 0.012290568596449954 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0052640264798186395                                     \n",
      "Min: 0.0052640264798186395                                     \n",
      "AVG: 0.005264026479818641 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.012290568596449954                                     \n",
      "Min: 0.012290568596449954                                     \n",
      "AVG: 0.012290568596449954 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.009729825884754946                                     \n",
      "Min: 0.009729825884754946                                     \n",
      "AVG: 0.009729825884754947 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.010210903130514558\n",
      "adjusted_rand_score: 0.00360761619803794\n",
      "v_measure_score: 0.010210903130514558\n",
      "homogeneity_score: 0.00832018095299523\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0181382474583357\n",
      "adjusted_rand_score: 0.0048508768229639605\n",
      "v_measure_score: 0.0181382474583357\n",
      "homogeneity_score: 0.013943148357864418\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.012501798263429717                                     \n",
      "Min: 0.012501798263429717                                     \n",
      "AVG: 0.012501798263429715 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00473193289685708                                     \n",
      "Min: 0.00473193289685708                                     \n",
      "AVG: 0.00473193289685708 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.01250179826342972                                     \n",
      "Min: 0.01250179826342972                                     \n",
      "AVG: 0.012501798263429717 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.009742327039290042                                     \n",
      "Min: 0.009742327039290042                                     \n",
      "AVG: 0.009742327039290042 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.012054427571642021\n",
      "adjusted_rand_score: 0.009594680277296784\n",
      "v_measure_score: 0.012054427571642023\n",
      "homogeneity_score: 0.010675526838282637\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.001226747365504667\n",
      "adjusted_rand_score: -1.0587941748039446e-05\n",
      "v_measure_score: 0.0012267473655046672\n",
      "homogeneity_score: 0.0006889997486384844\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.010064077425443203                                     \n",
      "Min: 0.009434549967958351                                     \n",
      "AVG: 0.009963353032245626 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0045560764908645565                                     \n",
      "Min: 0.004133260448118164                                     \n",
      "AVG: 0.004488425924025134 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.010064077425443203                                     \n",
      "Min: 0.009434549967958351                                     \n",
      "AVG: 0.009963353032245626 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.008820303034075109                                     \n",
      "Min: 0.008277231167166815                                     \n",
      "AVG: 0.008733411535369781 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.008538800630699978\n",
      "adjusted_rand_score: -0.00017777937309409472\n",
      "v_measure_score: 0.008538800630699976\n",
      "homogeneity_score: 0.0073425068709114276\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.010973732498471826\n",
      "adjusted_rand_score: -5.097733103210504e-05\n",
      "v_measure_score: 0.010973732498471828\n",
      "homogeneity_score: 0.008381314877773821\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.011723671041224919\n",
      "adjusted_rand_score: 0.004278008290523693\n",
      "v_measure_score: 0.011723671041224923\n",
      "homogeneity_score: 0.010107033451610474\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.006140232595915381                                     \n",
      "Min: 0.006140232595915381                                     \n",
      "AVG: 0.006140232595915381 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0020436721767025977                                     \n",
      "Min: 0.0020436721767025977                                     \n",
      "AVG: 0.0020436721767025973 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.006140232595915381                                     \n",
      "Min: 0.006140232595915381                                     \n",
      "AVG: 0.006140232595915381 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.004806759183058248                                     \n",
      "Min: 0.004806759183058248                                     \n",
      "AVG: 0.004806759183058249 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.008538800630699978\n",
      "adjusted_rand_score: -0.00017777937309409472\n",
      "v_measure_score: 0.008538800630699976\n",
      "homogeneity_score: 0.0073425068709114276\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.010973732498471826\n",
      "adjusted_rand_score: -5.097733103210504e-05\n",
      "v_measure_score: 0.010973732498471828\n",
      "homogeneity_score: 0.008381314877773821\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.007522310402967598                                     \n",
      "Min: 0.007522310402967598                                     \n",
      "AVG: 0.007522310402967596 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.002032008774006067                                     \n",
      "Min: 0.002032008774006067                                     \n",
      "AVG: 0.0020320087740060677 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.007522310402967598                                     \n",
      "Min: 0.007522310402967598                                     \n",
      "AVG: 0.007522310402967596 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.005732963091317436                                     \n",
      "Min: 0.005732963091317436                                     \n",
      "AVG: 0.005732963091317436 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0011230780621108482\n",
      "adjusted_rand_score: -0.0012399180091098802\n",
      "v_measure_score: 0.001123078062110848\n",
      "homogeneity_score: 0.000988189247498646\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.001936085328955761\n",
      "adjusted_rand_score: -0.0010284169523389645\n",
      "v_measure_score: 0.001936085328955761\n",
      "homogeneity_score: 0.0012906022605251755\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.019719537715158546                                     \n",
      "Min: 0.01903084446408215                                     \n",
      "AVG: 0.01929711604633734 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.023820592024979777                                     \n",
      "Min: 0.02286156438850615                                     \n",
      "AVG: 0.023259432565402628 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.019719537715158546                                     \n",
      "Min: 0.019030844464082146                                     \n",
      "AVG: 0.019297116046337336 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.018699721459789407                                     \n",
      "Min: 0.018039777964381037                                     \n",
      "AVG: 0.01829358188207751 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0043583936793787385\n",
      "adjusted_rand_score: 0.001922100811647575\n",
      "v_measure_score: 0.0043583936793787385\n",
      "homogeneity_score: 0.003691253688262369\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.012978277561973521\n",
      "adjusted_rand_score: 0.0036934119039662926\n",
      "v_measure_score: 0.012978277561973521\n",
      "homogeneity_score: 0.011432410017532556\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.01829939235528891                                     \n",
      "Min: 0.017262878376756254                                     \n",
      "AVG: 0.017580283880322845 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.018350714034583698                                     \n",
      "Min: 0.017316720208210713                                     \n",
      "AVG: 0.01763170091801965 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.01829939235528891                                     \n",
      "Min: 0.017262878376756254                                     \n",
      "AVG: 0.01758028388032284 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.016615057350615667                                     \n",
      "Min: 0.01559570440297824                                     \n",
      "AVG: 0.015909375713769613 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0043583936793787385\n",
      "adjusted_rand_score: 0.001922100811647575\n",
      "v_measure_score: 0.0043583936793787385\n",
      "homogeneity_score: 0.003691253688262369\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.02192176646328158                                     \n",
      "Min: 0.021374167352130963                                     \n",
      "AVG: 0.021463788751138222 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.020532926909221278                                     \n",
      "Min: 0.01978738981185778                                     \n",
      "AVG: 0.020150322619094 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.02192176646328158                                     \n",
      "Min: 0.021374167352130963                                     \n",
      "AVG: 0.02146378875113822 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.019423149832830815                                     \n",
      "Min: 0.01891106016880265                                     \n",
      "AVG: 0.019022563366738857 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.019951562308605574\n",
      "adjusted_rand_score: 0.0026002974391189522\n",
      "v_measure_score: 0.01995156230860557\n",
      "homogeneity_score: 0.01625608840320023\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.007323034960765204\n",
      "adjusted_rand_score: -0.00027428463624072896\n",
      "v_measure_score: 0.007323034960765204\n",
      "homogeneity_score: 0.003986126186497935\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0023964529504406757\n",
      "adjusted_rand_score: -0.0001294499202150984\n",
      "v_measure_score: 0.0023964529504406753\n",
      "homogeneity_score: 0.001209843047670891\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.016251709962566155                                     \n",
      "Min: 0.01604127580517543                                     \n",
      "AVG: 0.01605811053776669 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.006310791840584149                                     \n",
      "Min: 0.006228001314773791                                     \n",
      "AVG: 0.00623462455683862 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.016251709962566155                                     \n",
      "Min: 0.01604127580517543                                     \n",
      "AVG: 0.01605811053776669 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.013582898277998025                                     \n",
      "Min: 0.013426447133152199                                     \n",
      "AVG: 0.013438963224739864 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.014542082923446158\n",
      "adjusted_rand_score: 0.007133425648896996\n",
      "v_measure_score: 0.01454208292344616\n",
      "homogeneity_score: 0.012628581394262426\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.026588805120040686\n",
      "adjusted_rand_score: 0.011311625359973206\n",
      "v_measure_score: 0.02658880512004069\n",
      "homogeneity_score: 0.02101644615203457\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.022583415362554277\n",
      "adjusted_rand_score: 0.007129650734462833\n",
      "v_measure_score: 0.022583415362554274\n",
      "homogeneity_score: 0.017045752473870794\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.012647037267398383                                     \n",
      "Min: 0.012647037267398383                                     \n",
      "AVG: 0.012647037267398383 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0035095310462414254                                     \n",
      "Min: 0.0035095310462414254                                     \n",
      "AVG: 0.0035095310462414254 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.012647037267398383                                     \n",
      "Min: 0.012647037267398383                                     \n",
      "AVG: 0.012647037267398383 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.009774157705467763                                     \n",
      "Min: 0.009774157705467763                                     \n",
      "AVG: 0.009774157705467761 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.014542082923446158\n",
      "adjusted_rand_score: 0.007133425648896996\n",
      "v_measure_score: 0.01454208292344616\n",
      "homogeneity_score: 0.012628581394262426\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.026588805120040686\n",
      "adjusted_rand_score: 0.011311625359973206\n",
      "v_measure_score: 0.02658880512004069\n",
      "homogeneity_score: 0.02101644615203457\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.01169510885314781                                     \n",
      "Min: 0.011695108853147809                                     \n",
      "AVG: 0.01169510885314781 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0028136971034235445                                     \n",
      "Min: 0.0028136971034235445                                     \n",
      "AVG: 0.002813697103423545 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.01169510885314781                                     \n",
      "Min: 0.011695108853147809                                     \n",
      "AVG: 0.01169510885314781 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.00883436630098599                                     \n",
      "Min: 0.00883436630098599                                     \n",
      "AVG: 0.00883436630098599 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.011541623046169906\n",
      "adjusted_rand_score: 0.0020082887916981935\n",
      "v_measure_score: 0.011541623046169906\n",
      "homogeneity_score: 0.009646185048568031\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.003564391057722039\n",
      "adjusted_rand_score: -0.0003907507134412328\n",
      "v_measure_score: 0.003564391057722039\n",
      "homogeneity_score: 0.0021496216226340494\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "distilbert-base-uncased\n",
      "1575\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.010570257811638114                                     \n",
      "Min: 0.010056650074900983                                     \n",
      "AVG: 0.010085745344745553 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.008315420832683437                                     \n",
      "Min: 0.007845773319237267                                     \n",
      "AVG: 0.007870150385068622 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.010570257811638114                                     \n",
      "Min: 0.010056650074900983                                     \n",
      "AVG: 0.010085745344745553 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.008925613776710951                                     \n",
      "Min: 0.008498297245195371                                     \n",
      "AVG: 0.008522487365185594 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0029879060419321737\n",
      "adjusted_rand_score: 0.000675852440433475\n",
      "v_measure_score: 0.002987906041932174\n",
      "homogeneity_score: 0.001840690072891596\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0030789371011052716\n",
      "adjusted_rand_score: -0.0006671809431486217\n",
      "v_measure_score: 0.003078937101105272\n",
      "homogeneity_score: 0.0018176848393069022\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.008388046023438222\n",
      "adjusted_rand_score: 0.00762866563356032\n",
      "v_measure_score: 0.008388046023438222\n",
      "homogeneity_score: 0.007233475938435987\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0010706905733249576                                     \n",
      "Min: 0.0009293002671842288                                     \n",
      "AVG: 0.0009321280733070433 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.001015037883038898                                     \n",
      "Min: 0.0009359631728450755                                     \n",
      "AVG: 0.0009375446670489521 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0010706905733249576                                     \n",
      "Min: 0.0009293002671842288                                     \n",
      "AVG: 0.0009321280733070433 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.000874562166205013                                     \n",
      "Min: 0.0007490469962669952                                     \n",
      "AVG: 0.0007515572996657555 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0029879060419321737\n",
      "adjusted_rand_score: 0.000675852440433475\n",
      "v_measure_score: 0.002987906041932174\n",
      "homogeneity_score: 0.001840690072891596\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0030789371011052716\n",
      "adjusted_rand_score: -0.0006671809431486217\n",
      "v_measure_score: 0.003078937101105272\n",
      "homogeneity_score: 0.0018176848393069022\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0005059718044516802                                     \n",
      "Min: 0.0004784143016048759                                     \n",
      "AVG: 0.0005054206543947441 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 5.356898880687734e-05                                     \n",
      "Min: -0.0001307503215708095                                     \n",
      "AVG: -0.00012706393536325578 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0005059718044516802                                     \n",
      "Min: 0.0004784143016048759                                     \n",
      "AVG: 0.0005054206543947441 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0003816561482730084                                     \n",
      "Min: 0.00036339786400745294                                     \n",
      "AVG: 0.0003812909825876974 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.005758495869891715\n",
      "adjusted_rand_score: 0.004135913103931922\n",
      "v_measure_score: 0.005758495869891715\n",
      "homogeneity_score: 0.004958964392574925\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0007700293129300381\n",
      "adjusted_rand_score: -0.00016032393393400262\n",
      "v_measure_score: 0.000770029312930038\n",
      "homogeneity_score: 0.0004676399297840612\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.013737884722295906                                     \n",
      "Min: 0.013737884722295906                                     \n",
      "AVG: 0.013737884722295906 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.011846145938035587                                     \n",
      "Min: 0.011846145938035587                                     \n",
      "AVG: 0.011846145938035586 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.013737884722295906                                     \n",
      "Min: 0.013737884722295906                                     \n",
      "AVG: 0.013737884722295906 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.012067457677803893                                     \n",
      "Min: 0.012067457677803893                                     \n",
      "AVG: 0.012067457677803895 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0021445550278650933\n",
      "adjusted_rand_score: 0.0005251600325356202\n",
      "v_measure_score: 0.0021445550278650933\n",
      "homogeneity_score: 0.0017254337848541033\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.003072190152215242\n",
      "adjusted_rand_score: 6.861924363486147e-05\n",
      "v_measure_score: 0.003072190152215242\n",
      "homogeneity_score: 0.0017531721291477059\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.012213565547135187\n",
      "adjusted_rand_score: 0.0019373760995248708\n",
      "v_measure_score: 0.012213565547135189\n",
      "homogeneity_score: 0.009573580675975947\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0013833372194513895                                     \n",
      "Min: 0.0013181263052864398                                     \n",
      "AVG: 0.0013473628281894256 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0017544866072390507                                     \n",
      "Min: 0.001667962685273764                                     \n",
      "AVG: 0.0017076919429070275 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0013833372194513892                                     \n",
      "Min: 0.0013181263052864398                                     \n",
      "AVG: 0.0013473628281894256 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0011328293104207459                                     \n",
      "Min: 0.0010798704716889597                                     \n",
      "AVG: 0.0011040861871474878 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0021445550278650933\n",
      "adjusted_rand_score: 0.0005251600325356202\n",
      "v_measure_score: 0.0021445550278650933\n",
      "homogeneity_score: 0.0017254337848541033\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.003072190152215242\n",
      "adjusted_rand_score: 6.861924363486147e-05\n",
      "v_measure_score: 0.003072190152215242\n",
      "homogeneity_score: 0.0017531721291477059\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0011536511606701696                                     \n",
      "Min: 0.0010741205924752113                                     \n",
      "AVG: 0.0011520605493062703 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.000345568703077789                                     \n",
      "Min: 0.0002041982678305162                                     \n",
      "AVG: 0.00034274129437284346 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0011536511606701696                                     \n",
      "Min: 0.0010741205924752113                                     \n",
      "AVG: 0.0011520605493062703 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.000876433810288464                                     \n",
      "Min: 0.0008242276058602026                                     \n",
      "AVG: 0.0008753896861998988 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0007561290090568223\n",
      "adjusted_rand_score: 0.0002298354289376352\n",
      "v_measure_score: 0.0007561290090568223\n",
      "homogeneity_score: 0.0005213144898696667\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0058298120556899095\n",
      "adjusted_rand_score: 0.00023458725469270697\n",
      "v_measure_score: 0.0058298120556899095\n",
      "homogeneity_score: 0.0035818621044383476\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0026183193292056944\n",
      "adjusted_rand_score: 0.00011111680968432928\n",
      "v_measure_score: 0.0026183193292056944\n",
      "homogeneity_score: 0.001321851712732066\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.005479533508971023                                     \n",
      "Min: 0.00527750486725438                                     \n",
      "AVG: 0.005295340571336622 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.006870894272786042                                     \n",
      "Min: 0.006602541561033092                                     \n",
      "AVG: 0.006632149319347064 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.005479533508971023                                     \n",
      "Min: 0.00527750486725438                                     \n",
      "AVG: 0.005295340571336622 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.005014907984689228                                     \n",
      "Min: 0.004828259651194172                                     \n",
      "AVG: 0.004847007788050366 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.002740703313454271\n",
      "adjusted_rand_score: 0.003972536740876828\n",
      "v_measure_score: 0.0027407033134542714\n",
      "homogeneity_score: 0.002365213627948311\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0014245887052767988\n",
      "adjusted_rand_score: 0.0010130399732867516\n",
      "v_measure_score: 0.001424588705276799\n",
      "homogeneity_score: 0.0010305421770574943\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0024358403927627944\n",
      "adjusted_rand_score: -8.328054781015773e-05\n",
      "v_measure_score: 0.0024358403927627944\n",
      "homogeneity_score: 0.0012297276956253567\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.021403435424858293\n",
      "adjusted_rand_score: 0.027747345709817586\n",
      "v_measure_score: 0.02140343542485829\n",
      "homogeneity_score: 0.02049546279581938\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0028291709808431994                                     \n",
      "Min: 0.0028291709808431994                                     \n",
      "AVG: 0.0028291709808432 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.0032897137004751905                                     \n",
      "Min: 0.0032897137004751905                                     \n",
      "AVG: 0.00328971370047519 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0028291709808431994                                     \n",
      "Min: 0.0028291709808431994                                     \n",
      "AVG: 0.0028291709808432 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0023235246127948925                                     \n",
      "Min: 0.0023235246127948925                                     \n",
      "AVG: 0.002323524612794892 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.002740703313454271\n",
      "adjusted_rand_score: 0.003972536740876828\n",
      "v_measure_score: 0.0027407033134542714\n",
      "homogeneity_score: 0.002365213627948311\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0014245887052767988\n",
      "adjusted_rand_score: 0.0010130399732867516\n",
      "v_measure_score: 0.001424588705276799\n",
      "homogeneity_score: 0.0010305421770574943\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0024358403927627944\n",
      "adjusted_rand_score: -8.328054781015773e-05\n",
      "v_measure_score: 0.0024358403927627944\n",
      "homogeneity_score: 0.0012297276956253567\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0029602032932508496                                     \n",
      "Min: 0.0029602032932508496                                     \n",
      "AVG: 0.00296020329325085 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.004038378171039602                                     \n",
      "Min: 0.004038378171039602                                     \n",
      "AVG: 0.004038378171039602 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.002960203293250849                                     \n",
      "Min: 0.002960203293250849                                     \n",
      "AVG: 0.00296020329325085 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.0026653472470814423                                     \n",
      "Min: 0.0026653472470814423                                     \n",
      "AVG: 0.0026653472470814427 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0016451709853051407\n",
      "adjusted_rand_score: 0.0015280109488770661\n",
      "v_measure_score: 0.0016451709853051407\n",
      "homogeneity_score: 0.001389122071834704\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.0009554168678247025\n",
      "adjusted_rand_score: 0.001755165649495544\n",
      "v_measure_score: 0.0009554168678247025\n",
      "homogeneity_score: 0.0006894035037575721\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0025810389376197686\n",
      "adjusted_rand_score: 6.737740424806971e-05\n",
      "v_measure_score: 0.002581038937619769\n",
      "homogeneity_score: 0.001303030803869079\n",
      "\n",
      "start calculate\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.015529714014597077                                     \n",
      "Min: 0.015529714014597077                                     \n",
      "AVG: 0.015529714014597079 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.013217981344303692                                     \n",
      "Min: 0.013217981344303692                                     \n",
      "AVG: 0.013217981344303693 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.015529714014597079                                     \n",
      "Min: 0.015529714014597079                                     \n",
      "AVG: 0.01552971401459708 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.01342912183397881                                     \n",
      "Min: 0.01342912183397881                                     \n",
      "AVG: 0.01342912183397881 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.012720363773467537\n",
      "adjusted_rand_score: 0.006680364053338561\n",
      "v_measure_score: 0.012720363773467537\n",
      "homogeneity_score: 0.010731643238676645\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.002386208005694306\n",
      "adjusted_rand_score: -0.00038087234013851716\n",
      "v_measure_score: 0.002386208005694306\n",
      "homogeneity_score: 0.0013751734437033067\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n",
      "ward\n",
      "normalized_mutual_info_score: 0.0015677991631933709\n",
      "adjusted_rand_score: 0.00027779142096958466\n",
      "v_measure_score: 0.0015677991631933709\n",
      "homogeneity_score: 0.0013620200748927997\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0024191516337329173                                     \n",
      "Min: 0.0024191516337329173                                     \n",
      "AVG: 0.0024191516337329177 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.002609603814602825                                     \n",
      "Min: 0.002609603814602825                                     \n",
      "AVG: 0.002609603814602825 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0024191516337329173                                     \n",
      "Min: 0.0024191516337329173                                     \n",
      "AVG: 0.0024191516337329177 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.001998864678839409                                     \n",
      "Min: 0.001998864678839409                                     \n",
      "AVG: 0.001998864678839409 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.012720363773467537\n",
      "adjusted_rand_score: 0.006680364053338561\n",
      "v_measure_score: 0.012720363773467537\n",
      "homogeneity_score: 0.010731643238676645\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.002386208005694306\n",
      "adjusted_rand_score: -0.00038087234013851716\n",
      "v_measure_score: 0.002386208005694306\n",
      "homogeneity_score: 0.0013751734437033067\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n",
      "\n",
      "normalized_mutual_info_score \n",
      "Max: 0.0007608991351780662                                     \n",
      "Min: 0.0007142980896831337                                     \n",
      "AVG: 0.0007224719476938589 \n",
      "\n",
      "adjusted_rand_score \n",
      "Max: 0.00014308469929809672                                     \n",
      "Min: 1.7405937779213845e-05                                     \n",
      "AVG: 4.170638186913284e-05 \n",
      "\n",
      "v_measure_score \n",
      "Max: 0.0007608991351780662                                     \n",
      "Min: 0.0007142980896831337                                     \n",
      "AVG: 0.0007224719476938589 \n",
      "\n",
      "homogeneity_score \n",
      "Max: 0.000573360380326366                                     \n",
      "Min: 0.00053897979068245                                     \n",
      "AVG: 0.0005460839744391466 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.0034317312737279816\n",
      "adjusted_rand_score: 0.0007141717194292019\n",
      "v_measure_score: 0.0034317312737279816\n",
      "homogeneity_score: 0.00230018802456372\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.004728254609910368\n",
      "adjusted_rand_score: -0.000327728402216498\n",
      "v_measure_score: 0.004728254609910368\n",
      "homogeneity_score: 0.002830512491519912\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.0028053801933154206\n",
      "adjusted_rand_score: 0.00031037410111617845\n",
      "v_measure_score: 0.0028053801933154206\n",
      "homogeneity_score: 0.0014162889041206329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    kmeans_data, hierarchy_data = main(newsgroups, model_name)\n",
    "    \n",
    "    kmeans_data.to_excel(folder + model_name + \"/\" + kmeans_res_path)\n",
    "    hierarchy_data.to_excel(folder + model_name + \"/\" + hierarchy_res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "100.0%\n",
      "normalized_mutual_info_score \n",
      "Max: 0.8326760405064335                                     \n",
      "Min: 0.8326760405064335                                     \n",
      "AVG: 0.8326760405064334 \n",
      "\n",
      "\n",
      "complete\n",
      "normalized_mutual_info_score: 0.8326760405064335\n",
      "\n",
      "average\n",
      "normalized_mutual_info_score: 0.8326760405064335\n",
      "\n",
      "single\n",
      "normalized_mutual_info_score: 0.8326760405064335\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncomplete\\nnormalized_mutual_info_score: 0.8326760405064335\\n\\naverage\\nnormalized_mutual_info_score: 0.8326760405064335\\n\\nsingle\\nnormalized_mutual_info_score: 0.8326760405064335\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = [preprocess_text(text) for text in newsgroups.data[:5]]\n",
    "n = len(preprocessed_data)\n",
    "print(n)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text_vectors = []\n",
    "\n",
    "i = 0\n",
    "for sentence in preprocessed_data:\n",
    "    tokens = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sentence_vector = model(**tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    i+=1\n",
    "    print(str(round(i/n*100, 2)) + \"%\", end='\\r', flush=True)\n",
    "    text_vectors.append(sentence_vector.flatten().tolist())\n",
    "    \n",
    "\n",
    "# text_vectors = np.array(text_vectors)\n",
    "text_vectors = cosine_distances(text_vectors)\n",
    "\n",
    "true_labels = newsgroups.target[:5]\n",
    "metrics = [normalized_mutual_info_score]\n",
    "\n",
    "cluster_kmeans(text_vectors, metrics, true_labels, num_clusters=len(newsgroups.target_names))\n",
    "cluster_hierarchy(text_vectors, metrics, true_labels, num_clusters=len(newsgroups.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./newsgroups_bert/bert-base-uncased/kmeans_res_20News_light_bert.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|    | words         | euclidean                                                      | cosine                                                         |\n",
      "+====+===============+================================================================+================================================================+\n",
      "|  0 | all words     | normalized_mutual_info_score                                   | normalized_mutual_info_score                                   |\n",
      "|    |               | Max: 0.030803110968067524                                      | Max: 0.027385850481239375                                      |\n",
      "|    |               | Min: 0.03080311096806752                                       | Min: 0.027239055871528164                                      |\n",
      "|    |               | AVG: 0.030803110968067527                                      | AVG: 0.027297773715412647                                      |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | adjusted_rand_score                                            | adjusted_rand_score                                            |\n",
      "|    |               | Max: 0.0282510571257581                                        | Max: 0.023262698390237636                                      |\n",
      "|    |               | Min: 0.0282510571257581                                        | Min: 0.02311770715753595                                       |\n",
      "|    |               | AVG: 0.0282510571257581                                        | AVG: 0.023175703650616622                                      |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | v_measure_score                                                | v_measure_score                                                |\n",
      "|    |               | Max: 0.030803110968067524                                      | Max: 0.027385850481239378                                      |\n",
      "|    |               | Min: 0.030803110968067517                                      | Min: 0.027239055871528164                                      |\n",
      "|    |               | AVG: 0.030803110968067524                                      | AVG: 0.027297773715412647                                      |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | homogeneity_score                                              | homogeneity_score                                              |\n",
      "|    |               | Max: 0.02643603717867597                                       | Max: 0.02317393431766688                                       |\n",
      "|    |               | Min: 0.02643603717867597                                       | Min: 0.023052882580356485                                      |\n",
      "|    |               | AVG: 0.026436037178675972                                      | AVG: 0.023101303275280642                                      |\n",
      "+----+---------------+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|  1 | nouns         | normalized_mutual_info_score                                   | normalized_mutual_info_score                                   |\n",
      "|    |               | Max: 0.03729895163165697                                       | Max: 0.045089439771282526                                      |\n",
      "|    |               | Min: 0.03620265693013769                                       | Min: 0.04073626489805442                                       |\n",
      "|    |               | AVG: 0.03653352638722536                                       | AVG: 0.0437943444339812                                        |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | adjusted_rand_score                                            | adjusted_rand_score                                            |\n",
      "|    |               | Max: 0.0364245568705489                                        | Max: 0.045580991213949346                                      |\n",
      "|    |               | Min: 0.03508005869059842                                       | Min: 0.04024865260590191                                       |\n",
      "|    |               | AVG: 0.03550536095839069                                       | AVG: 0.0441581732377822                                        |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | v_measure_score                                                | v_measure_score                                                |\n",
      "|    |               | Max: 0.03729895163165697                                       | Max: 0.04508943977128252                                       |\n",
      "|    |               | Min: 0.03620265693013768                                       | Min: 0.04073626489805441                                       |\n",
      "|    |               | AVG: 0.036533526387225346                                      | AVG: 0.0437943444339812                                        |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | homogeneity_score                                              | homogeneity_score                                              |\n",
      "|    |               | Max: 0.032658131364503025                                      | Max: 0.040038605492277876                                      |\n",
      "|    |               | Min: 0.031794111885365114                                      | Min: 0.035891589567549745                                      |\n",
      "|    |               | AVG: 0.03203295704865294                                       | AVG: 0.039000748424869267                                      |\n",
      "+----+---------------+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|  2 | adj           | normalized_mutual_info_score                                   | normalized_mutual_info_score                                   |\n",
      "|    |               | Max: 0.04049274838494316                                       | Max: 0.03696500415307419                                       |\n",
      "|    |               | Min: 0.03992703479789508                                       | Min: 0.03643283389500152                                       |\n",
      "|    |               | AVG: 0.04043768563663771                                       | AVG: 0.03687328612005978                                       |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | adjusted_rand_score                                            | adjusted_rand_score                                            |\n",
      "|    |               | Max: 0.038170368975127475                                      | Max: 0.034382014697932804                                      |\n",
      "|    |               | Min: 0.03725409186022375                                       | Min: 0.033718055281612896                                      |\n",
      "|    |               | AVG: 0.038085512871858844                                      | AVG: 0.03426621745390835                                       |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | v_measure_score                                                | v_measure_score                                                |\n",
      "|    |               | Max: 0.040492748384943156                                      | Max: 0.03696500415307419                                       |\n",
      "|    |               | Min: 0.03992703479789508                                       | Min: 0.03643283389500152                                       |\n",
      "|    |               | AVG: 0.0404376856366377                                        | AVG: 0.03687328612005977                                       |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | homogeneity_score                                              | homogeneity_score                                              |\n",
      "|    |               | Max: 0.03767468199715156                                       | Max: 0.034292747734548254                                      |\n",
      "|    |               | Min: 0.03716645839684593                                       | Min: 0.0337910797847627                                        |\n",
      "|    |               | AVG: 0.03762480731053184                                       | AVG: 0.03419403396701867                                       |\n",
      "+----+---------------+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|  3 | nouns and adj | normalized_mutual_info_score                                   | normalized_mutual_info_score                                   |\n",
      "|    |               | Max: 0.04163665320808006                                       | Max: 0.04753767742599787                                       |\n",
      "|    |               | Min: 0.041636653208080056                                      | Min: 0.04229417221521328                                       |\n",
      "|    |               | AVG: 0.041636653208080056                                      | AVG: 0.04282789673221676                                       |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | adjusted_rand_score                                            | adjusted_rand_score                                            |\n",
      "|    |               | Max: 0.04039588781299458                                       | Max: 0.04756728076820383                                       |\n",
      "|    |               | Min: 0.04039588781299458                                       | Min: 0.04251447643060048                                       |\n",
      "|    |               | AVG: 0.04039588781299458                                       | AVG: 0.04290528083648                                          |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | v_measure_score                                                | v_measure_score                                                |\n",
      "|    |               | Max: 0.041636653208080056                                      | Max: 0.04753767742599787                                       |\n",
      "|    |               | Min: 0.041636653208080056                                      | Min: 0.042294172215213276                                      |\n",
      "|    |               | AVG: 0.04163665320808005                                       | AVG: 0.04282789673221676                                       |\n",
      "|    |               |                                                                |                                                                |\n",
      "|    |               | homogeneity_score                                              | homogeneity_score                                              |\n",
      "|    |               | Max: 0.03603448140959128                                       | Max: 0.042509330898566206                                      |\n",
      "|    |               | Min: 0.03603448140959128                                       | Min: 0.037340255122649234                                      |\n",
      "|    |               | AVG: 0.03603448140959128                                       | AVG: 0.03784594089052107                                       |\n",
      "+----+---------------+----------------------------------------------------------------+----------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(df, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
