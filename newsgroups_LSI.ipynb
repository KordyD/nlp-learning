{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    normalized_mutual_info_score,\n",
    "    adjusted_rand_score,\n",
    "    v_measure_score,\n",
    "    homogeneity_score,\n",
    ")\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation\n",
    "from gensim import corpora, models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.autos', 'sci.med',  'talk.politics.mideast']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [text.split() for text in lemm_texts]\n",
    "lemm_texts_nouns = [text.split() for text in lemm_texts_nouns]\n",
    "lemm_texts_nouns_adj = [text.split() for text in lemm_texts_nouns_adj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all = corpora.Dictionary(lemm_texts)\n",
    "dictionary_nouns = corpora.Dictionary(lemm_texts_nouns)\n",
    "dictionary_nouns_adj = corpora.Dictionary(lemm_texts_nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus_all = [dictionary_all.doc2bow(doc) for doc in lemm_texts]\n",
    "bow_corpus_nouns = [dictionary_nouns.doc2bow(doc) for doc in lemm_texts_nouns]\n",
    "bow_corpus_nouns_adj = [\n",
    "    dictionary_nouns_adj.doc2bow(doc) for doc in lemm_texts_nouns_adj\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LsiModel(bow_corpus_all, id2word=dictionary_all, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nouns = models.LsiModel(bow_corpus_nouns, id2word=dictionary_nouns, num_topics=10)\n",
    "model_nouns_adj = models.LsiModel(\n",
    "    bow_corpus_nouns_adj, id2word=dictionary_nouns_adj, num_topics=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors = []\n",
    "for doc_bow in bow_corpus_all:\n",
    "    document_topics = model[doc_bow]\n",
    "    document_topic_vector = [float(topic_prob) for _, topic_prob in document_topics]\n",
    "    if document_topic_vector == [] or len(document_topic_vector) < 10:\n",
    "        document_topic_vector = [random.uniform(-0.00001, 0.00001) for _ in range(10)]\n",
    "    text_vectors.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_nouns = []\n",
    "for doc_bow in bow_corpus_nouns:\n",
    "    document_topics = model[doc_bow]\n",
    "    document_topic_vector = [float(topic_prob) for _, topic_prob in document_topics]\n",
    "    if document_topic_vector == [] or len(document_topic_vector) < 10:\n",
    "        document_topic_vector = [random.uniform(-0.00001, 0.00001) for _ in range(10)]\n",
    "    text_vectors_nouns.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_nouns_adj = []\n",
    "for doc_bow in bow_corpus_nouns_adj:\n",
    "    document_topics = model[doc_bow]\n",
    "    document_topic_vector = [float(topic_prob) for _, topic_prob in document_topics]\n",
    "    if document_topic_vector == [] or len(document_topic_vector) < 10:\n",
    "        document_topic_vector = [random.uniform(-0.00001, 0.00001) for _ in range(10)]\n",
    "    text_vectors_nouns_adj.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance_matrix = euclidean_distances(text_vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(text_vectors_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(text_vectors_nouns_adj)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(text_vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(text_vectors_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(text_vectors_nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters):\n",
    "    scores = {}\n",
    "    result = []\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        clusters = KMeans(n_clusters=n_clusters, n_init=10, random_state=i)\n",
    "        clusters.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "\n",
    "    for metric in scores:\n",
    "        max = np.max(scores[metric])\n",
    "        min = np.min(scores[metric])\n",
    "        avg = np.mean(scores[metric])\n",
    "\n",
    "        result.append(f'{metric}\\nMax: {max} iter: {scores[metric].index(max) + 1}\\nMin: {min} iter: {scores[metric].index(min) + 1}\\nAvg: {avg}\\n')\n",
    "        # print(metric)\n",
    "        # print(f'Max: {max} iter: {scores[metric].index(max) + 1}')\n",
    "        # print(f'Min: {min} iter: {scores[metric].index(min) + 1}')\n",
    "        # print(f'Avg: {avg}')\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------------------------+------------------------------------+\n",
      "| words         | euclidean                          | cosine                             |\n",
      "+===============+====================================+====================================+\n",
      "| all words     | normalized_mutual_info_score       | normalized_mutual_info_score       |\n",
      "|               | Max: 0.012837984040047653 iter: 1  | Max: 0.19386014257970308 iter: 2   |\n",
      "|               | Min: 0.012837984040047653 iter: 1  | Min: 0.1929527505752893 iter: 1    |\n",
      "|               | Avg: 0.012837984040047653          | Avg: 0.19354791883337633           |\n",
      "|               |                                    |                                    |\n",
      "|               | adjusted_rand_score                | adjusted_rand_score                |\n",
      "|               | Max: 0.0007923689839791758 iter: 1 | Max: 0.135623113640441 iter: 2     |\n",
      "|               | Min: 0.0007923689839791758 iter: 1 | Min: 0.1344493683654122 iter: 1    |\n",
      "|               | Avg: 0.0007923689839791758         | Avg: 0.1351526266167526            |\n",
      "|               |                                    |                                    |\n",
      "|               | v_measure_score                    | v_measure_score                    |\n",
      "|               | Max: 0.012837984040047655 iter: 1  | Max: 0.19386014257970302 iter: 2   |\n",
      "|               | Min: 0.012837984040047655 iter: 1  | Min: 0.19295275057528932 iter: 1   |\n",
      "|               | Avg: 0.012837984040047653          | Avg: 0.19354791883337633           |\n",
      "|               |                                    |                                    |\n",
      "|               | homogeneity_score                  | homogeneity_score                  |\n",
      "|               | Max: 0.0069528668491806184 iter: 1 | Max: 0.16903627312091601 iter: 2   |\n",
      "|               | Min: 0.0069528668491806184 iter: 1 | Min: 0.1681123194642742 iter: 1    |\n",
      "|               | Avg: 0.0069528668491806184         | Avg: 0.16870850701054135           |\n",
      "+---------------+------------------------------------+------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score       | normalized_mutual_info_score       |\n",
      "|               | Max: 0.018194707963803017 iter: 1  | Max: 0.005586608057930679 iter: 5  |\n",
      "|               | Min: 0.016335700151127258 iter: 2  | Min: 0.005171909816234732 iter: 3  |\n",
      "|               | Avg: 0.01745110483873271           | Avg: 0.005336739805366772          |\n",
      "|               |                                    |                                    |\n",
      "|               | adjusted_rand_score                | adjusted_rand_score                |\n",
      "|               | Max: 0.0017915467773873736 iter: 1 | Max: 0.003211623298389793 iter: 5  |\n",
      "|               | Min: 0.0015487142379871015 iter: 2 | Min: 0.0027577495410224203 iter: 3 |\n",
      "|               | Avg: 0.0016944137616272648         | Avg: 0.002935307929010471          |\n",
      "|               |                                    |                                    |\n",
      "|               | v_measure_score                    | v_measure_score                    |\n",
      "|               | Max: 0.018194707963803017 iter: 1  | Max: 0.005586608057930678 iter: 5  |\n",
      "|               | Min: 0.016335700151127255 iter: 2  | Min: 0.005171909816234732 iter: 3  |\n",
      "|               | Avg: 0.01745110483873271           | Avg: 0.005336739805366772          |\n",
      "|               |                                    |                                    |\n",
      "|               | homogeneity_score                  | homogeneity_score                  |\n",
      "|               | Max: 0.010744610330409958 iter: 1  | Max: 0.005394790307042928 iter: 5  |\n",
      "|               | Min: 0.009549296684878542 iter: 2  | Min: 0.004987206081129065 iter: 3  |\n",
      "|               | Avg: 0.010266484872197392          | Avg: 0.005149439592021054          |\n",
      "+---------------+------------------------------------+------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score       | normalized_mutual_info_score       |\n",
      "|               | Max: 0.014028757029906547 iter: 1  | Max: 0.009816298002364417 iter: 1  |\n",
      "|               | Min: 0.012750451407947018 iter: 5  | Min: 0.009798060165905375 iter: 2  |\n",
      "|               | Avg: 0.01377309590551464           | Avg: 0.009812650435072607          |\n",
      "|               |                                    |                                    |\n",
      "|               | adjusted_rand_score                | adjusted_rand_score                |\n",
      "|               | Max: 0.0013346038032453287 iter: 1 | Max: 0.007173631498250693 iter: 1  |\n",
      "|               | Min: 0.0011319056620411798 iter: 5 | Min: 0.007168408941017107 iter: 2  |\n",
      "|               | Avg: 0.0012940641750044989         | Avg: 0.007172586986803976          |\n",
      "|               |                                    |                                    |\n",
      "|               | v_measure_score                    | v_measure_score                    |\n",
      "|               | Max: 0.014028757029906549 iter: 1  | Max: 0.009816298002364417 iter: 1  |\n",
      "|               | Min: 0.012750451407947016 iter: 5  | Min: 0.009798060165905375 iter: 2  |\n",
      "|               | Avg: 0.01377309590551464           | Avg: 0.009812650435072607          |\n",
      "|               |                                    |                                    |\n",
      "|               | homogeneity_score                  | homogeneity_score                  |\n",
      "|               | Max: 0.008108031686546318 iter: 1  | Max: 0.00903918220032807 iter: 1   |\n",
      "|               | Min: 0.007336201291016688 iter: 5  | Min: 0.009023576252027123 iter: 2  |\n",
      "|               | Avg: 0.007953665607440392          | Avg: 0.009036061010667881          |\n",
      "+---------------+------------------------------------+------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = [ 'euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    result = []\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        result.append('\\n')\n",
    "        result.append(linkage)\n",
    "        result.append('---------')\n",
    "        # print(linkage)\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            result.append(f\"{metric.__name__}: {score}\")\n",
    "            # print(f\"{metric.__name__}: \", score)\n",
    "\n",
    "        # plt.figure(figsize=[12, 12])\n",
    "        # plt.subplot(4, 1, linkages.index(linkage) + 1)\n",
    "        # children = agg_clustering.children_\n",
    "        # distance = np.arange(children.shape[0])\n",
    "        # num_of_observations = np.arange(2, children.shape[0] + 2)\n",
    "        # linkage_matrix = np.column_stack([children, distance, num_of_observations]).astype(float)\n",
    "        # dendrogram(linkage_matrix)\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "    # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "| words         | euclidean                                          | cosine                                              |\n",
      "+===============+====================================================+=====================================================+\n",
      "| all words     | complete                                           | complete                                            |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.006609383262860259 | normalized_mutual_info_score: 0.0047403127867715195 |\n",
      "|               | adjusted_rand_score: 5.535400422572383e-05         | adjusted_rand_score: 1.60894136149029e-05           |\n",
      "|               | v_measure_score: 0.006609383262860259              | v_measure_score: 0.0047403127867715195              |\n",
      "|               | homogeneity_score: 0.0033660793442008862           | homogeneity_score: 0.0026721489008559446            |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | average                                            | average                                             |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.00559136935253825  | normalized_mutual_info_score: 0.003475074360785294  |\n",
      "|               | adjusted_rand_score: 3.169570963761392e-05         | adjusted_rand_score: -9.11860541782645e-06          |\n",
      "|               | v_measure_score: 0.005591369352538249              | v_measure_score: 0.003475074360785294               |\n",
      "|               | homogeneity_score: 0.0028397254128408626           | homogeneity_score: 0.0018698045494805727            |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | single                                             | single                                              |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.003070587117070722 | normalized_mutual_info_score: 0.0015471088278736934 |\n",
      "|               | adjusted_rand_score: 1.6336494810068106e-05        | adjusted_rand_score: 1.2431573398911465e-05         |\n",
      "|               | v_measure_score: 0.003070587117070722              | v_measure_score: 0.0015471088278736934              |\n",
      "|               | homogeneity_score: 0.0015497801224426471           | homogeneity_score: 0.0007775397013106913            |\n",
      "+---------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "| adj and nouns | complete                                           | complete                                            |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.007525212198943749 | normalized_mutual_info_score: 0.013332101577603214  |\n",
      "|               | adjusted_rand_score: -1.2316857515392443e-05       | adjusted_rand_score: 0.004240931606844685           |\n",
      "|               | v_measure_score: 0.0075252121989437485             | v_measure_score: 0.013332101577603214               |\n",
      "|               | homogeneity_score: 0.0038408907323397743           | homogeneity_score: 0.009528908399807315             |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | average                                            | average                                             |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.008022015530237958 | normalized_mutual_info_score: 0.002834722791064105  |\n",
      "|               | adjusted_rand_score: -7.833645828047982e-06        | adjusted_rand_score: 5.730708663567302e-06          |\n",
      "|               | v_measure_score: 0.008022015530237958              | v_measure_score: 0.002834722791064105               |\n",
      "|               | homogeneity_score: 0.0040989296327544455           | homogeneity_score: 0.0015534965857218043            |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | single                                             | single                                              |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.003550401420861617 | normalized_mutual_info_score: 0.0015212189806090425 |\n",
      "|               | adjusted_rand_score: -5.645045267334041e-06        | adjusted_rand_score: -1.1526338598359016e-05        |\n",
      "|               | v_measure_score: 0.0035504014208616176             | v_measure_score: 0.0015212189806090425              |\n",
      "|               | homogeneity_score: 0.0017938920482876998           | homogeneity_score: 0.000764528086518988             |\n",
      "+---------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "| nouns         | complete                                           | complete                                            |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.005118803129957175 | normalized_mutual_info_score: 0.002959649134491897  |\n",
      "|               | adjusted_rand_score: 1.5730511676332608e-05        | adjusted_rand_score: 0.00019522620251989983         |\n",
      "|               | v_measure_score: 0.005118803129957176              | v_measure_score: 0.002959649134491897               |\n",
      "|               | homogeneity_score: 0.0026253092529927497           | homogeneity_score: 0.001779931437220688             |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | average                                            | average                                             |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.005025978521390015 | normalized_mutual_info_score: 0.0038634762137153313 |\n",
      "|               | adjusted_rand_score: 1.427607982353853e-05         | adjusted_rand_score: 5.8116524268335935e-05         |\n",
      "|               | v_measure_score: 0.005025978521390015              | v_measure_score: 0.003863476213715331               |\n",
      "|               | homogeneity_score: 0.0025562454181751234           | homogeneity_score: 0.002164295051029444             |\n",
      "|               |                                                    |                                                     |\n",
      "|               |                                                    |                                                     |\n",
      "|               | single                                             | single                                              |\n",
      "|               | ---------                                          | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.003070587117070722 | normalized_mutual_info_score: 0.0015212189806090425 |\n",
      "|               | adjusted_rand_score: 1.6336494810068106e-05        | adjusted_rand_score: -1.1526338598359016e-05        |\n",
      "|               | v_measure_score: 0.003070587117070722              | v_measure_score: 0.0015212189806090425              |\n",
      "|               | homogeneity_score: 0.0015497801224426471           | homogeneity_score: 0.000764528086518988             |\n",
      "+---------------+----------------------------------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = [ 'euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------------------+-------------------------------------+\n",
      "|               | euclidean                            | cosine                              |\n",
      "+===============+======================================+=====================================+\n",
      "| all words     | normalized_mutual_info_score         | normalized_mutual_info_score        |\n",
      "|               | Max: 0.011588837175748943 iter: 1    | Max: 0.03744183192772247 iter: 3    |\n",
      "|               | Min: 0.011588837175748943 iter: 1    | Min: 0.03608768375925906 iter: 1    |\n",
      "|               | Avg: 0.011588837175748943            | Avg: 0.036485809487247195           |\n",
      "|               |                                      |                                     |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 |\n",
      "|               | Max: -0.00019766272151510464 iter: 1 | Max: 0.023167454617220435 iter: 3   |\n",
      "|               | Min: -0.00019766272151510464 iter: 1 | Min: 0.01986871238952054 iter: 2    |\n",
      "|               | Avg: -0.0001976627215151046          | Avg: 0.020655271023164938           |\n",
      "|               |                                      |                                     |\n",
      "|               | v_measure_score                      | v_measure_score                     |\n",
      "|               | Max: 0.011588837175748943 iter: 1    | Max: 0.03744183192772246 iter: 3    |\n",
      "|               | Min: 0.011588837175748943 iter: 1    | Min: 0.03608768375925906 iter: 1    |\n",
      "|               | Avg: 0.011588837175748943            | Avg: 0.036485809487247195           |\n",
      "|               |                                      |                                     |\n",
      "|               | homogeneity_score                    | homogeneity_score                   |\n",
      "|               | Max: 0.006561757946873703 iter: 1    | Max: 0.029794102803694836 iter: 3   |\n",
      "|               | Min: 0.006561757946873703 iter: 1    | Min: 0.02807230399557745 iter: 1    |\n",
      "|               | Avg: 0.006561757946873703            | Avg: 0.028482430727433127           |\n",
      "+---------------+--------------------------------------+-------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score         | normalized_mutual_info_score        |\n",
      "|               | Max: 0.006924952005311038 iter: 1    | Max: 0.003824664737453233 iter: 5   |\n",
      "|               | Min: 0.006924952005311038 iter: 1    | Min: 0.0026536874286146855 iter: 1  |\n",
      "|               | Avg: 0.006924952005311039            | Avg: 0.003072387061299814           |\n",
      "|               |                                      |                                     |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 |\n",
      "|               | Max: 6.0921064548152395e-05 iter: 1  | Max: 0.004313696497296501 iter: 5   |\n",
      "|               | Min: 6.0921064548152395e-05 iter: 1  | Min: 0.002845035622624678 iter: 1   |\n",
      "|               | Avg: 6.0921064548152395e-05          | Avg: 0.003346244149372444           |\n",
      "|               |                                      |                                     |\n",
      "|               | v_measure_score                      | v_measure_score                     |\n",
      "|               | Max: 0.006924952005311039 iter: 1    | Max: 0.0038246647374532328 iter: 5  |\n",
      "|               | Min: 0.006924952005311039 iter: 1    | Min: 0.0026536874286146855 iter: 1  |\n",
      "|               | Avg: 0.006924952005311039            | Avg: 0.0030723870612998144          |\n",
      "|               |                                      |                                     |\n",
      "|               | homogeneity_score                    | homogeneity_score                   |\n",
      "|               | Max: 0.003962259810058834 iter: 1    | Max: 0.003663505886550904 iter: 5   |\n",
      "|               | Min: 0.003962259810058834 iter: 1    | Min: 0.002530944642607196 iter: 1   |\n",
      "|               | Avg: 0.003962259810058834            | Avg: 0.0029362237617295887          |\n",
      "+---------------+--------------------------------------+-------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score         | normalized_mutual_info_score        |\n",
      "|               | Max: 0.007714228239123266 iter: 1    | Max: 0.0007412401449369392 iter: 3  |\n",
      "|               | Min: 0.007714228239123266 iter: 1    | Min: 0.0004872560051554917 iter: 2  |\n",
      "|               | Avg: 0.007714228239123266            | Avg: 0.0006826804269230923          |\n",
      "|               |                                      |                                     |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 |\n",
      "|               | Max: -7.057138108289749e-06 iter: 1  | Max: 0.0006737579779984497 iter: 1  |\n",
      "|               | Min: -7.057138108289749e-06 iter: 1  | Min: 0.00012008628446952364 iter: 2 |\n",
      "|               | Avg: -7.05713810828975e-06           | Avg: 0.0005437491236112273          |\n",
      "|               |                                      |                                     |\n",
      "|               | v_measure_score                      | v_measure_score                     |\n",
      "|               | Max: 0.007714228239123266 iter: 1    | Max: 0.0007412401449369391 iter: 3  |\n",
      "|               | Min: 0.007714228239123266 iter: 1    | Min: 0.00048725600515549174 iter: 2 |\n",
      "|               | Avg: 0.007714228239123266            | Avg: 0.0006826804269230922          |\n",
      "|               |                                      |                                     |\n",
      "|               | homogeneity_score                    | homogeneity_score                   |\n",
      "|               | Max: 0.004685056998379723 iter: 1    | Max: 0.0006402680340447891 iter: 3  |\n",
      "|               | Min: 0.004685056998379723 iter: 1    | Min: 0.00041995118776141666 iter: 2 |\n",
      "|               | Avg: 0.004685056998379723            | Avg: 0.0005898630819271198          |\n",
      "+---------------+--------------------------------------+-------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                               |\n",
      "+===============+=====================================================+======================================================+\n",
      "| all words     | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.006561090240526184  | normalized_mutual_info_score: 0.0023368840105066064  |\n",
      "|               | adjusted_rand_score: 0.000646427144291917           | adjusted_rand_score: 0.0012058651643825499           |\n",
      "|               | v_measure_score: 0.0065610902405261835              | v_measure_score: 0.002336884010506607                |\n",
      "|               | homogeneity_score: 0.0033459869400902713            | homogeneity_score: 0.0013267787224578234             |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.00408103288938652   | normalized_mutual_info_score: 0.0010445367768047793  |\n",
      "|               | adjusted_rand_score: 0.00035106567249213307         | adjusted_rand_score: 0.0006580548871424211           |\n",
      "|               | v_measure_score: 0.004081032889386521               | v_measure_score: 0.0010445367768047793               |\n",
      "|               | homogeneity_score: 0.002068065949550337             | homogeneity_score: 0.0005610469554191763             |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0015762914621453169  |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 6.683166511636353e-05           |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0015762914621453169               |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007930105083651363             |\n",
      "+---------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.002855752487571417  | normalized_mutual_info_score: 0.0005482679674748103  |\n",
      "|               | adjusted_rand_score: -0.00011301610700657591        | adjusted_rand_score: -0.0007196209513013607          |\n",
      "|               | v_measure_score: 0.0028557524875714164              | v_measure_score: 0.0005482679674748103               |\n",
      "|               | homogeneity_score: 0.0014508716895509453            | homogeneity_score: 0.00032047292897043885            |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.00292039421279127   | normalized_mutual_info_score: 0.0015477688321762595  |\n",
      "|               | adjusted_rand_score: -2.1488499017563052e-05        | adjusted_rand_score: -0.00030734022832879394         |\n",
      "|               | v_measure_score: 0.0029203942127912705              | v_measure_score: 0.0015477688321762595               |\n",
      "|               | homogeneity_score: 0.0014869476690422053            | homogeneity_score: 0.0008518256294177183             |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0014659570011457048 | normalized_mutual_info_score: 0.0013241214188988938  |\n",
      "|               | adjusted_rand_score: -5.033080642229187e-05         | adjusted_rand_score: 1.4271100187231096e-05          |\n",
      "|               | v_measure_score: 0.0014659570011457048              | v_measure_score: 0.0013241214188988938               |\n",
      "|               | homogeneity_score: 0.0007375027617911531            | homogeneity_score: 0.0006678711128773175             |\n",
      "+---------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0024869006550149284 | normalized_mutual_info_score: 0.00046454153463839905 |\n",
      "|               | adjusted_rand_score: 0.0005359276285531435          | adjusted_rand_score: 0.0001744426073370948           |\n",
      "|               | v_measure_score: 0.0024869006550149284              | v_measure_score: 0.000464541534638399                |\n",
      "|               | homogeneity_score: 0.001287263263396504             | homogeneity_score: 0.0002738805099242306             |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0024869006550149284 | normalized_mutual_info_score: 0.001127445297472877   |\n",
      "|               | adjusted_rand_score: 0.0005359276285531435          | adjusted_rand_score: -0.00020376483345426594         |\n",
      "|               | v_measure_score: 0.0024869006550149284              | v_measure_score: 0.001127445297472877                |\n",
      "|               | homogeneity_score: 0.001287263263396504             | homogeneity_score: 0.000624191470961975              |\n",
      "|               |                                                     |                                                      |\n",
      "|               |                                                     |                                                      |\n",
      "|               | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.001553853019830139  | normalized_mutual_info_score: 0.0014210558150619882  |\n",
      "|               | adjusted_rand_score: 4.060126104054516e-05          | adjusted_rand_score: -0.00010279161457392863         |\n",
      "|               | v_measure_score: 0.001553853019830139               | v_measure_score: 0.0014210558150619884               |\n",
      "|               | homogeneity_score: 0.0007817220373084805            | homogeneity_score: 0.0007149135939516061             |\n",
      "+---------------+-----------------------------------------------------+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
