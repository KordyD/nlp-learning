{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    normalized_mutual_info_score,\n",
    "    adjusted_rand_score,\n",
    "    v_measure_score,\n",
    "    homogeneity_score,\n",
    ")\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.autos', 'sci.med',  'talk.politics.mideast']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cleaned_collection = [re.sub(r'[\\n\\t]+| {2,}', ' ', text) for text in news_groups.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import stop_words\n",
    "\n",
    "stop_words = stop_words.STOP_WORDS\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "token_collection= []\n",
    "vector = []\n",
    "\n",
    "lemmatized_collection = [[(token.lemma_.lower(), token.pos_) for token in nlp(text) if token.lemma_.lower() not in stop_words and token.lemma_.lower() not in punctuations and not token.pos_ == 'PUNCT' and not token.pos_ == 'SPACE'] for text in cleaned_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts_nouns = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]\n",
    "\n",
    "lemm_texts_nouns_adj = [' '.join(text) for text in [\n",
    "    [token[0] for token in lemmatized_text if token[1] == \"NOUN\" or token[1] == \"ADJ\"]\n",
    "    for lemmatized_text in lemmatized_collection\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_texts = [text.split() for text in lemm_texts]\n",
    "lemm_texts_nouns = [text.split() for text in lemm_texts_nouns]\n",
    "lemm_texts_nouns_adj = [text.split() for text in lemm_texts_nouns_adj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all = corpora.Dictionary(lemm_texts)\n",
    "dictionary_nouns = corpora.Dictionary(lemm_texts_nouns)\n",
    "dictionary_nouns_adj = corpora.Dictionary(lemm_texts_nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus_all = [dictionary_all.doc2bow(doc) for doc in lemm_texts]\n",
    "bow_corpus_nouns = [dictionary_nouns.doc2bow(doc) for doc in lemm_texts_nouns]\n",
    "bow_corpus_nouns_adj = [\n",
    "    dictionary_nouns_adj.doc2bow(doc) for doc in lemm_texts_nouns_adj\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LdaModel(\n",
    "    bow_corpus_all, id2word=dictionary_all, num_topics=10, passes=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nouns = models.LdaModel(\n",
    "    bow_corpus_nouns, id2word=dictionary_nouns, num_topics=10, passes=15\n",
    ")\n",
    "model_nouns_adj = models.LdaModel(\n",
    "    bow_corpus_nouns_adj, id2word=dictionary_nouns_adj, num_topics=10, passes=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors = []\n",
    "for doc_bow in bow_corpus_all:\n",
    "    document_topics = model.get_document_topics(doc_bow)\n",
    "    document_topic_vector = [topic_prob for _, topic_prob in document_topics]\n",
    "    text_vectors.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_nouns = []\n",
    "for doc_bow in bow_corpus_nouns:\n",
    "    document_topics = model_nouns.get_document_topics(doc_bow)\n",
    "    document_topic_vector = [topic_prob for _, topic_prob in document_topics]\n",
    "    text_vectors_nouns.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors_nouns_adj = []\n",
    "for doc_bow in bow_corpus_nouns_adj:\n",
    "    document_topics = model_nouns_adj.get_document_topics(doc_bow)\n",
    "    document_topic_vector = [topic_prob for _, topic_prob in document_topics]\n",
    "    text_vectors_nouns_adj.append(document_topic_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance_matrix = euclidean_distances(text_vectors)\n",
    "euclidean_distance_matrix_adj_nouns = euclidean_distances(text_vectors_nouns)\n",
    "euclidean_distance_matrix_nouns = euclidean_distances(text_vectors_nouns_adj)\n",
    "\n",
    "cosine_distance_matrix = cosine_distances(text_vectors)\n",
    "cosine_distance_matrix_adj_nouns = cosine_distances(text_vectors_nouns)\n",
    "cosine_distance_matrix_nouns = cosine_distances(text_vectors_nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = news_groups.target\n",
    "n_clusters = len(news_groups.target_names)\n",
    "n_iterations = 50\n",
    "matrixes = [euclidean_distance_matrix, cosine_distance_matrix]\n",
    "matrixes_adj_nouns = [euclidean_distance_matrix_adj_nouns, cosine_distance_matrix_adj_nouns]\n",
    "matrixes_nouns = [euclidean_distance_matrix_nouns, cosine_distance_matrix_nouns]\n",
    "metrics = [normalized_mutual_info_score, adjusted_rand_score, v_measure_score, homogeneity_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters):\n",
    "    scores = {}\n",
    "    result = []\n",
    "    for metric in metrics:\n",
    "        scores.update({metric.__name__: []})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        clusters = KMeans(n_clusters=n_clusters, n_init=10, random_state=i)\n",
    "        clusters.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, clusters.labels_)\n",
    "            scores[metric.__name__].append(score)\n",
    "\n",
    "\n",
    "    for metric in scores:\n",
    "        max = np.max(scores[metric])\n",
    "        min = np.min(scores[metric])\n",
    "        avg = np.mean(scores[metric])\n",
    "\n",
    "        result.append(f'{metric}\\nMax: {max} iter: {scores[metric].index(max) + 1}\\nMin: {min} iter: {scores[metric].index(min) + 1}\\nAvg: {avg}\\n')\n",
    "        # print(metric)\n",
    "        # print(f'Max: {max} iter: {scores[metric].index(max) + 1}')\n",
    "        # print(f'Min: {min} iter: {scores[metric].index(min) + 1}')\n",
    "        # print(f'Avg: {avg}')\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------------------+----------------------------------+\n",
      "| words         | euclidean                        | cosine                           |\n",
      "+===============+==================================+==================================+\n",
      "| all words     | normalized_mutual_info_score     | normalized_mutual_info_score     |\n",
      "|               | Max: 0.34879373468230035 iter: 1 | Max: 0.45075554749625896 iter: 1 |\n",
      "|               | Min: 0.34879373468230035 iter: 1 | Min: 0.38331162859740525 iter: 2 |\n",
      "|               | Avg: 0.34879373468230035         | Avg: 0.3970446384979763          |\n",
      "|               |                                  |                                  |\n",
      "|               | adjusted_rand_score              | adjusted_rand_score              |\n",
      "|               | Max: 0.30369951005543305 iter: 1 | Max: 0.4608616764082237 iter: 1  |\n",
      "|               | Min: 0.30369951005543305 iter: 1 | Min: 0.37914346245909464 iter: 2 |\n",
      "|               | Avg: 0.30369951005543305         | Avg: 0.39583436248724657         |\n",
      "|               |                                  |                                  |\n",
      "|               | v_measure_score                  | v_measure_score                  |\n",
      "|               | Max: 0.3487937346823003 iter: 1  | Max: 0.45075554749625896 iter: 1 |\n",
      "|               | Min: 0.3487937346823003 iter: 1  | Min: 0.3833116285974052 iter: 2  |\n",
      "|               | Avg: 0.3487937346823003          | Avg: 0.3970446384979763          |\n",
      "|               |                                  |                                  |\n",
      "|               | homogeneity_score                | homogeneity_score                |\n",
      "|               | Max: 0.3416827223768381 iter: 1  | Max: 0.4461119769803778 iter: 1  |\n",
      "|               | Min: 0.3416827223768381 iter: 1  | Min: 0.381097661200663 iter: 2   |\n",
      "|               | Avg: 0.3416827223768381          | Avg: 0.39434825177343386         |\n",
      "+---------------+----------------------------------+----------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score     | normalized_mutual_info_score     |\n",
      "|               | Max: 0.4446535688648319 iter: 1  | Max: 0.470485743679504 iter: 5   |\n",
      "|               | Min: 0.44465356886483187 iter: 3 | Min: 0.4701528694961533 iter: 1  |\n",
      "|               | Avg: 0.44465356886483187         | Avg: 0.4702194443328235          |\n",
      "|               |                                  |                                  |\n",
      "|               | adjusted_rand_score              | adjusted_rand_score              |\n",
      "|               | Max: 0.32683893565271543 iter: 1 | Max: 0.41700859798909995 iter: 5 |\n",
      "|               | Min: 0.32683893565271543 iter: 1 | Min: 0.41647964941012394 iter: 1 |\n",
      "|               | Avg: 0.32683893565271543         | Avg: 0.41658543912591917         |\n",
      "|               |                                  |                                  |\n",
      "|               | v_measure_score                  | v_measure_score                  |\n",
      "|               | Max: 0.4446535688648319 iter: 1  | Max: 0.470485743679504 iter: 5   |\n",
      "|               | Min: 0.4446535688648318 iter: 3  | Min: 0.47015286949615326 iter: 1 |\n",
      "|               | Avg: 0.44465356886483187         | Avg: 0.4702194443328234          |\n",
      "|               |                                  |                                  |\n",
      "|               | homogeneity_score                | homogeneity_score                |\n",
      "|               | Max: 0.42116645189150304 iter: 1 | Max: 0.4582913858707797 iter: 5  |\n",
      "|               | Min: 0.42116645189150304 iter: 1 | Min: 0.4579330111486765 iter: 1  |\n",
      "|               | Avg: 0.4211664518915031          | Avg: 0.45800468609309714         |\n",
      "+---------------+----------------------------------+----------------------------------+\n",
      "| nouns         | normalized_mutual_info_score     | normalized_mutual_info_score     |\n",
      "|               | Max: 0.48226948517605445 iter: 1 | Max: 0.4865269321453035 iter: 2  |\n",
      "|               | Min: 0.48226948517605445 iter: 1 | Min: 0.4859802912179538 iter: 1  |\n",
      "|               | Avg: 0.4822694851760544          | Avg: 0.48630827577436364         |\n",
      "|               |                                  |                                  |\n",
      "|               | adjusted_rand_score              | adjusted_rand_score              |\n",
      "|               | Max: 0.4297986760882278 iter: 1  | Max: 0.4947414447570606 iter: 2  |\n",
      "|               | Min: 0.4297986760882278 iter: 1  | Min: 0.4943323814591945 iter: 1  |\n",
      "|               | Avg: 0.4297986760882278          | Avg: 0.4945778194379142          |\n",
      "|               |                                  |                                  |\n",
      "|               | v_measure_score                  | v_measure_score                  |\n",
      "|               | Max: 0.48226948517605445 iter: 1 | Max: 0.48652693214530357 iter: 2 |\n",
      "|               | Min: 0.48226948517605445 iter: 1 | Min: 0.48598029121795383 iter: 1 |\n",
      "|               | Avg: 0.4822694851760544          | Avg: 0.4863082757743637          |\n",
      "|               |                                  |                                  |\n",
      "|               | homogeneity_score                | homogeneity_score                |\n",
      "|               | Max: 0.47002565191944745 iter: 1 | Max: 0.48289055227638067 iter: 2 |\n",
      "|               | Min: 0.47002565191944745 iter: 1 | Min: 0.482371597201275 iter: 1   |\n",
      "|               | Avg: 0.47002565191944745         | Avg: 0.4826829702463383          |\n",
      "+---------------+----------------------------------+----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def cluster_hierarchy(matrix, metrics, true_labels, num_clusters):\n",
    "    linkages = [\"complete\", \"average\", \"single\"]\n",
    "    result = []\n",
    "\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        affinity = \"euclidean\"\n",
    "        matrix = matrix.toarray()\n",
    "        linkages.append(\"ward\")\n",
    "    else:\n",
    "        affinity = \"precomputed\"\n",
    "\n",
    "    for linkage in linkages:\n",
    "        result.append('\\n')\n",
    "        result.append(linkage)\n",
    "        result.append('---------')\n",
    "        # print(linkage)\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, metric=affinity, linkage=linkage)\n",
    "\n",
    "        agg_clustering.fit(matrix)\n",
    "\n",
    "        for metric in metrics:\n",
    "            score = metric(true_labels, agg_clustering.labels_)\n",
    "            result.append(f\"{metric.__name__}: {score}\")\n",
    "            # print(f\"{metric.__name__}: \", score)\n",
    "\n",
    "        # plt.figure(figsize=[12, 12])\n",
    "        # plt.subplot(4, 1, linkages.index(linkage) + 1)\n",
    "        # children = agg_clustering.children_\n",
    "        # distance = np.arange(children.shape[0])\n",
    "        # num_of_observations = np.arange(2, children.shape[0] + 2)\n",
    "        # linkage_matrix = np.column_stack([children, distance, num_of_observations]).astype(float)\n",
    "        # dendrogram(linkage_matrix)\n",
    "\n",
    "    return '\\n'.join(result)\n",
    "\n",
    "    # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              |\n",
      "+===============+=====================================================+=====================================================+\n",
      "| all words     | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.14155381144358758   | normalized_mutual_info_score: 0.1641302538171248    |\n",
      "|               | adjusted_rand_score: 0.052034622348958504           | adjusted_rand_score: 0.047452619900946486           |\n",
      "|               | v_measure_score: 0.14155381144358758                | v_measure_score: 0.16413025381712482                |\n",
      "|               | homogeneity_score: 0.11194050792656518              | homogeneity_score: 0.12490042590721691              |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.274395583157467     | normalized_mutual_info_score: 0.39483805486602663   |\n",
      "|               | adjusted_rand_score: 0.18759245517215414            | adjusted_rand_score: 0.37322502406415586            |\n",
      "|               | v_measure_score: 0.274395583157467                  | v_measure_score: 0.39483805486602663                |\n",
      "|               | homogeneity_score: 0.2152447585650445               | homogeneity_score: 0.35386931412781075              |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015215918283552972 | normalized_mutual_info_score: 0.00430988882782699   |\n",
      "|               | adjusted_rand_score: -1.1174016363105039e-05        | adjusted_rand_score: 5.182948420124396e-06          |\n",
      "|               | v_measure_score: 0.0015215918283552974              | v_measure_score: 0.00430988882782699                |\n",
      "|               | homogeneity_score: 0.0007647154708322531            | homogeneity_score: 0.0023925267445538264            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.2478857992520738    | normalized_mutual_info_score: 0.2825048154628757    |\n",
      "|               | adjusted_rand_score: 0.14594366229172526            | adjusted_rand_score: 0.21453163069622624            |\n",
      "|               | v_measure_score: 0.24788579925207377                | v_measure_score: 0.2825048154628757                 |\n",
      "|               | homogeneity_score: 0.20465720983035932              | homogeneity_score: 0.2564546171263216               |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.3785041338573743    | normalized_mutual_info_score: 0.4608989453032099    |\n",
      "|               | adjusted_rand_score: 0.3033755304892797             | adjusted_rand_score: 0.44881161050440066            |\n",
      "|               | v_measure_score: 0.37850413385737425                | v_measure_score: 0.4608989453032099                 |\n",
      "|               | homogeneity_score: 0.3385760683357458               | homogeneity_score: 0.4543072293119758               |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.0015152015678878844 | normalized_mutual_info_score: 0.003263406278193441  |\n",
      "|               | adjusted_rand_score: -1.716349436242266e-05         | adjusted_rand_score: 0.00011555231835259557         |\n",
      "|               | v_measure_score: 0.0015152015678878846              | v_measure_score: 0.003263406278193441               |\n",
      "|               | homogeneity_score: 0.0007615038795559247            | homogeneity_score: 0.0018677109203186816            |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.40297600616092216   | normalized_mutual_info_score: 0.24018441864919415   |\n",
      "|               | adjusted_rand_score: 0.329355859768917              | adjusted_rand_score: 0.23149689560211645            |\n",
      "|               | v_measure_score: 0.4029760061609221                 | v_measure_score: 0.24018441864919413                |\n",
      "|               | homogeneity_score: 0.3576201370642282               | homogeneity_score: 0.22051499187808551              |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | average                                             | average                                             |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.404073546087286     | normalized_mutual_info_score: 0.40203306734910554   |\n",
      "|               | adjusted_rand_score: 0.3120734589188783             | adjusted_rand_score: 0.3292580021203603             |\n",
      "|               | v_measure_score: 0.404073546087286                  | v_measure_score: 0.4020330673491055                 |\n",
      "|               | homogeneity_score: 0.3502115978968735               | homogeneity_score: 0.3530649259451776               |\n",
      "|               |                                                     |                                                     |\n",
      "|               |                                                     |                                                     |\n",
      "|               | single                                              | single                                              |\n",
      "|               | ---------                                           | ---------                                           |\n",
      "|               | normalized_mutual_info_score: 0.001515947640756944  | normalized_mutual_info_score: 0.0036129010750199997 |\n",
      "|               | adjusted_rand_score: -1.6458849891914702e-05        | adjusted_rand_score: 0.00011146702450853304         |\n",
      "|               | v_measure_score: 0.001515947640756944               | v_measure_score: 0.00361290107502                   |\n",
      "|               | homogeneity_score: 0.0007618788378428358            | homogeneity_score: 0.002056705602303869             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc']\n",
    "news_groups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| words         | euclidean                            | cosine                              | jaccard                              |\n",
      "+===============+======================================+=====================================+======================================+\n",
      "| all words     | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.00989720425486164 iter: 27    | Max: 0.06705030887874189 iter: 16   | Max: 0.0024613566626412752 iter: 34  |\n",
      "|               | Min: 0.00867397313342348 iter: 44    | Min: 0.06589595692174573 iter: 30   | Min: 0.0006243085014123848 iter: 26  |\n",
      "|               | Avg: 0.009237487871880801            | Avg: 0.06650649272880205            | Avg: 0.0009126573425607214           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.004704129796147561 iter: 27   | Max: 0.008630883496648617 iter: 16  | Max: 0.0018278135815092765 iter: 16  |\n",
      "|               | Min: 0.003732048748137828 iter: 44   | Min: 0.007756438538600965 iter: 1   | Min: 0.0003506146941817634 iter: 34  |\n",
      "|               | Avg: 0.004108176295301857            | Avg: 0.008170286920124748           | Avg: 0.0014210634854765719           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.00989720425486164 iter: 27    | Max: 0.06705030887874189 iter: 16   | Max: 0.0024613566626412752 iter: 34  |\n",
      "|               | Min: 0.00867397313342348 iter: 44    | Min: 0.06589595692174573 iter: 30   | Min: 0.0006243085014123848 iter: 26  |\n",
      "|               | Avg: 0.009237487871880801            | Avg: 0.06650649272880205            | Avg: 0.0009126573425607214           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.00826297426681117 iter: 27    | Max: 0.05886385664527416 iter: 16   | Max: 0.001529892311851259 iter: 34   |\n",
      "|               | Min: 0.00724058882580948 iter: 44    | Min: 0.05761572225092139 iter: 30   | Min: 0.00041562583820666817 iter: 26 |\n",
      "|               | Avg: 0.007707741380639321            | Avg: 0.05821246249389416            | Avg: 0.0006062721690794969           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| adj and nouns | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.00965331190974325 iter: 23    | Max: 0.0898939751319832 iter: 21    | Max: 0.0009792645190992368 iter: 14  |\n",
      "|               | Min: 0.008765948647461662 iter: 38   | Min: 0.05606041387688407 iter: 31   | Min: 0.000763872115459146 iter: 1    |\n",
      "|               | Avg: 0.009232484140775581            | Avg: 0.05969590182747653            | Avg: 0.0008292563375671927           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.0026760376413390774 iter: 23  | Max: 0.028233394276724763 iter: 21  | Max: 0.0006842656016879369 iter: 32  |\n",
      "|               | Min: 0.002023452490170424 iter: 38   | Min: 0.0046916331430225024 iter: 31 | Min: 0.00044523980286530635 iter: 1  |\n",
      "|               | Avg: 0.0022839416838921645           | Avg: 0.006480334629779371           | Avg: 0.0005404916646942859           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.00965331190974325 iter: 23    | Max: 0.08989397513198319 iter: 21   | Max: 0.0009792645190992368 iter: 14  |\n",
      "|               | Min: 0.00876594864746166 iter: 38    | Min: 0.056060413876884076 iter: 31  | Min: 0.000763872115459146 iter: 1    |\n",
      "|               | Avg: 0.009232484140775581            | Avg: 0.05969590182747653            | Avg: 0.0008292563375671927           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.00804883504938617 iter: 23    | Max: 0.07826375419193418 iter: 21   | Max: 0.0007019757286300856 iter: 14  |\n",
      "|               | Min: 0.0073016782922253895 iter: 38  | Min: 0.04827873827074757 iter: 31   | Min: 0.0005513163338560846 iter: 1   |\n",
      "|               | Avg: 0.007688538893868752            | Avg: 0.051532939796837256           | Avg: 0.0005948785073507602           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n",
      "| nouns         | normalized_mutual_info_score         | normalized_mutual_info_score        | normalized_mutual_info_score         |\n",
      "|               | Max: 0.005894490336502347 iter: 16   | Max: 0.06917376697580999 iter: 48   | Max: 0.001891746795442741 iter: 39   |\n",
      "|               | Min: 0.004223612710640147 iter: 2    | Min: 0.06718552182376501 iter: 7    | Min: 0.0014945191047373368 iter: 13  |\n",
      "|               | Avg: 0.005472682138522197            | Avg: 0.06739769480531951            | Avg: 0.0017184885339054654           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | adjusted_rand_score                  | adjusted_rand_score                 | adjusted_rand_score                  |\n",
      "|               | Max: 0.0007351645977886789 iter: 16  | Max: 0.01378145523393777 iter: 48   | Max: 0.0010536684126072453 iter: 39  |\n",
      "|               | Min: -3.0583477695435496e-05 iter: 2 | Min: 0.013045446051232203 iter: 25  | Min: 0.0007943082094913861 iter: 13  |\n",
      "|               | Avg: 0.0004950908910843203           | Avg: 0.013165680231496425           | Avg: 0.0009212451235968242           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | v_measure_score                      | v_measure_score                     | v_measure_score                      |\n",
      "|               | Max: 0.0058944903365023464 iter: 16  | Max: 0.06917376697581 iter: 48      | Max: 0.001891746795442741 iter: 39   |\n",
      "|               | Min: 0.004223612710640147 iter: 2    | Min: 0.06718552182376501 iter: 7    | Min: 0.0014945191047373368 iter: 13  |\n",
      "|               | Avg: 0.005472682138522197            | Avg: 0.06739769480531951            | Avg: 0.0017184885339054654           |\n",
      "|               |                                      |                                     |                                      |\n",
      "|               | homogeneity_score                    | homogeneity_score                   | homogeneity_score                    |\n",
      "|               | Max: 0.004962963734849487 iter: 16   | Max: 0.06027994029935692 iter: 48   | Max: 0.0013740305236002212 iter: 39  |\n",
      "|               | Min: 0.003570435237151268 iter: 2    | Min: 0.05865823606300129 iter: 7    | Min: 0.0010882842348435106 iter: 13  |\n",
      "|               | Avg: 0.004610743562689432            | Avg: 0.05883699697657002            | Avg: 0.0012505079356201132           |\n",
      "+---------------+--------------------------------------+-------------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_kmeans(matrix, metrics, true_labels, n_iterations, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| words         | euclidean                                           | cosine                                              | jaccard                                              |\n",
      "+===============+=====================================================+=====================================================+======================================================+\n",
      "| all words     | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.01757673451070667   | normalized_mutual_info_score: 0.023622156850907686  | normalized_mutual_info_score: 0.0027278125516680633  |\n",
      "|               | adjusted_rand_score: 0.0021760001055478474          | adjusted_rand_score: 0.001837123289824085           | adjusted_rand_score: -8.689118235675604e-05          |\n",
      "|               | v_measure_score: 0.01757673451070667                | v_measure_score: 0.023622156850907686               | v_measure_score: 0.002727812551668063                |\n",
      "|               | homogeneity_score: 0.011062998099638023             | homogeneity_score: 0.012731992686354797             | homogeneity_score: 0.0013827301538634417             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.001553853019830139  | normalized_mutual_info_score: 0.0008054224458444695 | normalized_mutual_info_score: 0.0010870405332491571  |\n",
      "|               | adjusted_rand_score: 4.060126104054516e-05          | adjusted_rand_score: 0.00021036812992633776         | adjusted_rand_score: -0.0007299558796045252          |\n",
      "|               | v_measure_score: 0.001553853019830139               | v_measure_score: 0.0008054224458444695              | v_measure_score: 0.001087040533249157                |\n",
      "|               | homogeneity_score: 0.0007817220373084805            | homogeneity_score: 0.00044966569252644805           | homogeneity_score: 0.0007408559822426252             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0014210558150619882 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0014210558150619882  |\n",
      "|               | adjusted_rand_score: -0.00010279161457392863        | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.00010279161457392863         |\n",
      "|               | v_measure_score: 0.0014210558150619884              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0014210558150619884               |\n",
      "|               | homogeneity_score: 0.0007149135939516061            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007149135939516061             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| adj and nouns | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.005672998188794483  | normalized_mutual_info_score: 0.011515808410836041  | normalized_mutual_info_score: 0.004982305225326041   |\n",
      "|               | adjusted_rand_score: 0.0025244250833076107          | adjusted_rand_score: 0.0011864098114761777          | adjusted_rand_score: 0.00034206380158647627          |\n",
      "|               | v_measure_score: 0.005672998188794484               | v_measure_score: 0.011515808410836041               | v_measure_score: 0.004982305225326041                |\n",
      "|               | homogeneity_score: 0.003320145167906631             | homogeneity_score: 0.005968756260198418             | homogeneity_score: 0.002542821519466101              |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0008799911685924768 | normalized_mutual_info_score: 0.0001910933188094951  |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.0003053617512556256         | adjusted_rand_score: -0.00012027845969144645         |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0008799911685924768              | v_measure_score: 0.00019109331880949506              |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0005078437955248916            | homogeneity_score: 0.00013441492234374055            |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0015762914621453169  |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 6.683166511636353e-05           |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.0015762914621453169               |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0007930105083651363             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n",
      "| nouns         | complete                                            | complete                                            | complete                                             |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.01501136042713871   | normalized_mutual_info_score: 0.007462845128208882  | normalized_mutual_info_score: 0.004982305225326041   |\n",
      "|               | adjusted_rand_score: 0.010264379914473782           | adjusted_rand_score: 0.0006658021000663491          | adjusted_rand_score: 0.00034206380158647627          |\n",
      "|               | v_measure_score: 0.01501136042713871                | v_measure_score: 0.007462845128208882               | v_measure_score: 0.004982305225326041                |\n",
      "|               | homogeneity_score: 0.012866792481229372             | homogeneity_score: 0.003832203952715021             | homogeneity_score: 0.002542821519466101              |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | average                                             | average                                             | average                                              |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.0011001374298359229 | normalized_mutual_info_score: 0.00033462651606586043 |\n",
      "|               | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: -0.00044992845219088667        | adjusted_rand_score: -0.0006545312868381451          |\n",
      "|               | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.001100137429835923               | v_measure_score: 0.00033462651606586043              |\n",
      "|               | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0006409149693020832            | homogeneity_score: 0.0002355105636743708             |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               |                                                     |                                                     |                                                      |\n",
      "|               | single                                              | single                                              | single                                               |\n",
      "|               | ---------                                           | ---------                                           | ---------                                            |\n",
      "|               | normalized_mutual_info_score: 0.0014210558150619882 | normalized_mutual_info_score: 0.0015762914621453169 | normalized_mutual_info_score: 0.001688279862522615   |\n",
      "|               | adjusted_rand_score: -0.00010279161457392863        | adjusted_rand_score: 6.683166511636353e-05          | adjusted_rand_score: 0.0001857428302600735           |\n",
      "|               | v_measure_score: 0.0014210558150619884              | v_measure_score: 0.0015762914621453169              | v_measure_score: 0.001688279862522615                |\n",
      "|               | homogeneity_score: 0.0007149135939516061            | homogeneity_score: 0.0007930105083651363            | homogeneity_score: 0.0008493503290435613             |\n",
      "+---------------+-----------------------------------------------------+-----------------------------------------------------+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['euclidean', 'cosine']\n",
    "\n",
    "arr = [['all words'], ['adj and nouns'], ['nouns']]\n",
    "\n",
    "for matrix in matrixes:\n",
    "    arr[0].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_adj_nouns:\n",
    "    arr[1].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "for matrix in matrixes_nouns:\n",
    "    arr[2].append(cluster_hierarchy(matrix, metrics, true_labels, n_clusters))\n",
    "\n",
    "print(tabulate(arr, headers, tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
